Смысл устойчивости в том, что что-то способно выдержать трудные времена и прийти в норму.
Рассмотрим проблемы, которые хотим решить:
![[Pasted image 20241205165451.png]]
1. Наши микросервисы редко могут выполнить всю работу самостоятельно. Они часто общаются с другими микросервисами для получения доп информации или выполнения каких-то дополнительных действий. Поэтому нам нужно настроить механизмы, чтобы если в цепочке вызовов для выполнения запроса клиента один из микросервисов зафейлился(он мог упасть или могли произойти проблемы с сетью или он в целом мог долго отвечать на запрос), то мы не хотим, чтобы это убило всю цепочку вызовов.
2. Мы должны написать какой-то fallback(запасной) механизм на случай, если один из микросервисов в цепочке не может выполнить запрос. Мы узнаем какие механизмы существуют для реализации этих fallback механизмов.
3. Мы хотим уметь предоставить возможность микросервису, который по каким-то причинам заболел)) и не может ответить нам на запрос возможность восстановиться. Это может быть дополнительные попытки сделать запрос. Например, первый запрос мог не дойти из-за сетевой проблемы, а второй запрос без проблем дошел. Также мы можем захотеть реализовать механизм timeout-ов, чтобы не постоянно спамить запросами на микросервис, который мог перестать работать из-за повышенной нагрузки, а дать ему время на выполнения других запросв и потом он сможет и наш запрос также выполнить. 

### Решение
Использовать библиотеку Resilience4j, которая как раз и дает возможность создавать устойчивые микросервисы и решить проблемы, описанные выше.
![[Pasted image 20241205170302.png]]

### Пример проблемы, в которой потребуется использование Resilience4J
![[Pasted image 20241205171030.png]]
В accounts microservice есть endpoint - /fetchCustomerDetails, который требует от accounts microservice общения с cards и loans. Но представим, что cards микросервис не отвечает. Т.е. мы послали запрос и ждем ответа, а он все не приходит и не приходит. Что имеем? У нас в accounts микросервисе thread, в котором выполнялся запрос простаиваем в ожидании, что влияет на performance всего микросервиса, т.к. параллельно в accounts микросервис обращаются другие клиенты. Но это не все! Т.к. Api Gateway ожидает ответ от accounts, в который он перенаправил запрос, то у него также простаивает thread, который ждет ответа, чтобы отправить клиенту.

Как решить? Мы можем использовать Circuit Breaker Pattern.

### [[Circuit Breaker Pattern]]

### HTTP Timeout
Если мы не пользуемся Circuit Breaker, поставим точку остановка в контроллере, который выполняет обрабатывает запрос, то увидим в postman следующее:
![[Pasted image 20241206121804.png]]
Но, что, если мы хотим настроить максимальное время ожидания, но при этом не использовать Circuit Breaker механизм? 
Т.к. весь трафик ходить снаружи через Gateway, то настроим timeout именно в нем, т.к. он обращаеся к микросервисам. Добавим настройку в application.yml - она будет глобальной на все микросервисы к которым обращается Gateway.
![[Pasted image 20241206122557.png]]
Теперь вместо ожидания вечного, как было до этого в примере с postman выше, мы будем получать:
![[Pasted image 20241206123006.png]]
При этом глобальная настройка не будет влиять на circuit breaker, который мы настроили. Он будет главнее 
![[Pasted image 20241206123137.png]]
Если мы хотим уметь настраивать timeout в зависимости от пути, то в routing, который мы прописывали мы можем указать metadata и там указать настройки. Тогда для пути, который указан в route будут применяться они. Если указать response-timeout = -1, то тогда не будут применяться глобальные настройки и в таком случае timeout будет вечным.
![[Pasted image 20241206123412.png]]
### [[Retry Pattern]]

### [[Rate Limitter Pattern]]

### [[Bulkhead Pattern]]

### Порядок выполнения Resilience паттернов
Вот мы и изучили Resilience паттерны. Но, в каком порядке они выполняются, если мы применяем сразу несколько из них одновременно на один API?
Дефолтная последовательность выполнения, которой будет следовать Resilience4j:
![[Pasted image 20241206171039.png]]
Первым выполняется Bulkhead -> TimeLimiter -> RateLimiter -> CircuitBreaker -> Retry.

Но если нас это не устраивает, то мы можем поменять порядок. 
![[Pasted image 20241206171209.png]]

### Docker compose
Добавляем redis, т.к. он нужен для Spring Cloud Gateway Rate Limiter. Также добавляем healthcheck для того, чтобы только после успешного запуска редиса мы запускали наш Gateway, т.к. он теперь зависит от него.
![[Pasted image 20241206171501.png]]

В Gateway добавляем зависимость на redis и также через environment добавляем настройки для подключения.
![[Pasted image 20241206171655.png]]
