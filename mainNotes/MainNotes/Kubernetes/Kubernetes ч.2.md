Эта часть направлена на то, как наше приложение разворачивается, как поддерживать состояние приложения, их количество инстансов и обновления.

### ReplicationController
До этого мы разворачивали приложения, создавая поды вручную. Но это не оптимальный способ. Например, если упадет нода, на которой работал pod, то никто не будет пытаться поднять новую.
Но есть ReplicationController, который будет следить за количеством запущенных pod. 
![[Pasted image 20241212140723.png]]
Создаем новый блок типа - ReplicationController
![[Pasted image 20241212141026.png]]
У нас есть replicas и selector, в котором мы указываем, сколько реплик подов с label app и значением notes должно всегда быть в системе. И в случае падения поды, он может поднять новую.
Причем если мы попытаемся потом вруную поднять доп поды с label app=notes(больше, чем указано в replicas), то ReplicationController их не даст поднять и будет убивать, т.к. в нем точно указано, сколько подов должно быть с таким лейблом.

### ReplicaSet
ReplicationController - старый объект и его уже никто не использует. На замену ему пришел ReplicaSet.
![[Pasted image 20241212141637.png]]
Разница от ReplicaController в том, как он работает с селекторами. 

В ReplicaSet появился mathLabels, который по функионалу такой же, как в ReplicaCOntroller. где мы его не писали, а сразу указывали app: notes. Зачем это доп прослойка? Потому что есть еще matchExpression, с помощью которого можно задавать выражения, вычисляющие нужно ли относится поду к этой группе, за которую ответственен ReplicaSet или нет.
![[Pasted image 20241212141852.png]]

Попробуем воспользоваться matchExpression. Создадим вручную 2 поды для attachments. У обоих будет label app: attachments. А также у них будет label env. Который у одной поды равен prod, а у другой test.
![[Pasted image 20241212142149.png]]

![[Pasted image 20241212142425.png]]

Настроим ReplicaSet. Он следит именно за теми подами, у которые label соотвествует тем правилам, которые мы написали. Т.е. не важно, что за контейнер внутри и функционал, он смотрит чисто на label.
![[Pasted image 20241212142757.png]]

Мы не рассмотрели секцию template в ReplicaController и ReplicaSet.
template нужен для указания того, как нужно создать поду, если вдруг ее не хватает.
Т.е. это шаблон создания поды.
Вот пример template:
![[Pasted image 20241212142944.png]]

Но есть минус у всего этого? Что делать, если мы хотим обновить версию нашего приложения, при этом мы не хотим, чтобы у наших пользователей какое-то время ничего не работало. Если мы просто в template укажем новую версию image, то это не поможет. Да, новые поды будут создаваться уже с новой версией, но старые продолжат работать на старой версии и для того, чтобы обновиться нам нужно будет сначала вырубить старую поду, чтобы ReplicaSet из-за параметра replica понял, что нужно создать новую поду и уже новая пода будет с новой версией. Но это же все никак не автоматизировано.

Как автоматизировать? Использовать другой блок - deployment.
### Deployment
Deployment создает ReplicaSet, которая уже создает поды. И особенностью является то, что он умеет обновляться. 
![[Pasted image 20241212161453.png]]
Ниже на скрине приведен код описания Deployment. Тут также есть селекторы. И template. И вот если мы в template в image укажем новую версию, то deployment создаст ReplicaSet и уже этот ReplicaSet поднимет новые версии, а после этого ReplicaSet старый потушит старые версии.

(Тут на скрине v4, но перед запуска Deployment мы поменяли версию image на 5)
![[Pasted image 20241212163920.png]]
Вот такое получится, после того, как мы 
![[Pasted image 20241212165007.png]]

А если произошел трабл? Т.е. развернули новую версию приложения и поняли, что она нерабочая и нужно срочно вернуться на предыдущую версию.
Для этого нужно ввести команду:
kubectl rollout undo deployment notes-deployment.

И после этого он в deployment у ReplicaSet 5-ой версии снизит количество подов, до 0, а у ReplicaSet 4-ой версии увеличит количество подов до 2.
![[Pasted image 20241212165441.png]]

Второй способ - это удалить deployment, который удаляет все связанные с ним ReplicaSet, а ReplicaSet удаляет все связанные с ним поды.

Но тут есть проблема, связанная с тем, что приложение может долго запускаться. А кубер он создал поды и запустил приложение(не дожидаясь, когда оно полностью стартанет) и потушил старые поды. И поэтому в этот момент пользователи уже не могут работать с нашим приложением.

В Deployment есть настройка minReadySeconds - которая указывает, сколько секунд минимум pod будет готов принимать запросы  и не нужно раньше этого времени тушить поды прошлой версии и перенаправлять трафик в новые поды.
![[Pasted image 20241212171151.png]]

Но тут схема такая, что он поднимает 1 под новой версии, убывает 1 под старой версии, потом ждет 40 сек поднимает 1 под новой версии, тушит 1 под старой версии. И это довольно долгий процесс, ведь подов может быть и 10 штук. Но и на этот случай есть параметр в deployment:
У deployment есть две стратегии развертывания:
![[Pasted image 20241212171716.png]]
- Recreate - убивает все предыдущие поды деплоймента и после этого создаем новые. Это может быть полезно на тестовых контурах, где мало ресурсов. Ведь в случае RollingUpdate, когда создается новая пода, потом убивается старая ресурсов на создание новой поды может не хватить(с учетом того, что мы старые не убиваем, пока новая пода не поднимется). 
- RollingUpdate - стратегия по умолчанию. А у rollingUpdate есть еще две настройки.
	- maxUnavailable - максимальное количество недоступных подов.
	- maxSurge - сколько подов можем поднимать сразу, при переходе на новую версию.
Пример:
![[Pasted image 20241212172617.png]]
maxUnavailable = 3 говорит о том, что максимум 3 поды будут недоступны, а всего у нас 5 реплик под, поэтому 2 должны быть доступны всегда.

Вот, что произойдет на следующем шаге. 3 пода старой версии стали недоступны(maxUnavailable=3) и сразу 2 пода новой версии начинают подниматься.
![[Pasted image 20241212172812.png]]
После того, как новые поды поднялись - старые убились, т.к. теперь доступны 2 пода новой версии, а это нам подходит. При этом поднялись еще 2 пода новой версии ну и в конечном итоге все 5 реплик под будут новой версии.
![[Pasted image 20241212172951.png]]

Но помимо того, что приложение может долго стартовать, оно может еще и долго выключаться, закрывая соединения с БД и все такое. Есть настройка в deployment, которой можно задать сколько секунд кубер будет ждать того, когда приложение остановится. И если за эти секунды приложение не будет остановлено, то он его принудительно выключит сразу же, не дожидаясь.
![[Pasted image 20241212173631.png]]


Идем дальше. Пусть наше приложение может стартануть за время от 5 до 40 секунд.
Но еще приложение может упасть в течение работы и перестать отвечать на запросы.
А значит, надо кубернетесу дать понять, что под умер и иди, что-нибудь сделай. В общем, мы хотим механизм, который позволил мы следить за тем, готово приложение или нет.

И такой способ есть - мы можем тыкать под палкой спрашивать, ну ты там готов или нет?) И это тыканье называется probe. Бывает несколько видов этих пробов.

#### ReadinessProbe
Это даже скорее не чисто deployment настройка, а получается уже настройка контейнера, как если бы мы в docker-compose писали такие же проверки.
ReadinessProbe дергает какой-то эндпоинт в заданное время и если на этот эндпоинт наше приложение не отвечает, то кубернетес перестает передавать трафик в этот под.
![[Pasted image 20241212175236.png]]
initalDelaySeconds - через сколько секунд начать слать запросы для проверки. Т.е. мы можем знать, что под точно за 5 секунд не поднимется, поэтому нет смысла начинать опрашивать его о том, готов он или нет.
periodSeconds - как часто опрашивать pod
faillureThreshold - порог ошибок. Сколько раз под может не ответить на проверку readisnessProbe. Если это значение равно 1, то если под не ответил на первую проверку, то он исключается и к нему запросы пользователя не пойдут.

Мы можем как задать команду через exec, которая будет вызываться для проверки, так и какой-то endpoint по которому будет обращение.
![[Pasted image 20241213102920.png]]
Эндпоинт, как я понял, должен просто 200 код вернуть, если с приложением все хорошо.

И сейчас логика такая, что мы переходим на новую версию, она разворачивается и пока она не развернулась(т.е. readisneeProbe не прошел, то весь трафик будет на старых версиях, а потом только, когда readinessProbe проверил наше приложение и оно оказалось готово для принятия запросов, то уже трафик перенаправил в поды с новой версией). 

Но сейчас, если пода перестанет отвечать на readinessProbe, то в нее перестанет идти трафик, но при этом кубернетес не перезапустит это под. А вот для того, чтобы принялось решение о перезапуске всей поды, нужен еще один probe - livenessProbe:
![[Pasted image 20241213103715.png]]
Через 45 секунд начинаем проверку пода, если 2-ды не ответил на запрос, то мы его убиваем.

Итог - различие readinessProbe и livenessProbe в том, что если не прошла проверка readiness, то трафик перестает поступать в этот под, но под не перезапускается. А в livenessProbe, если проверка не прошла, то перезапускается под.

### Resources
У нас есть 3 worker ноды. Синеньким - занятая память.
![[Pasted image 20241213104244.png]]
И в первой worker node пытается создаться под, которому не хватает доступных 500мб, и он не запускается и падает с ошибкой.
![[Pasted image 20241213104349.png]]
Как решить проблему? При описании пода можно задать информацию о том, сколько ресурса нужно для запуска пода(request memory) и тогда он будет запускаться на той ноде, на которой этот ресурс есть.

Но за request memory под может выходить. Т.е. например, request memory: 1000, то мы выделили ему место на 1000 мб, но он может за него выйти:
![[Pasted image 20241213104737.png]]
А чтобы не выходил за какой-то предел, то должны задать limit. Задаем эти параметры в параметрах контейнера.
![[Pasted image 20241213104856.png]]
requests - сколько гарантировано дадим ресурсов, а limits - больше этого точно не дадим. Начнешь хавать больше - мы тебя убьем)
500mi - это 500 мегабайт памяти.
1000m - милликор(тоже самое, что 1-ца. Т.е. всего 1 процессор.) Представим, что на машине есть 12 ядер и если мы дадим 1000m, то это означает, что мы дадим ему ресурсы одного ядра.
![[Pasted image 20241213105225.png]]
![[Pasted image 20241213105250.png]]
Единица i говорит, что используется именно 1024(это связано с тем, что приставка кило - это 1000, но в программировании пошло все не так и 1мегайбайт это 1024 килобайта, а не 1000килобайт). И в общем, чтобы пофиксить это они ввели i в конце, которая указывает, что когда мы пишем Mi, то это именно 1024килобайта, а если мы пишем просто M, то это 1000 килобайт.

### Job
![[Pasted image 20241213105757.png]]
В случае нашего приложения с заметками, которое мы развиваем мы хотим, чтобы была джоба, которая запустилась 1 раз, удалила самые старые 5 заметок и завершить свою работу.
Создаем джобу:
Но для нее нужно указывать обязательно restartPolicy - она есть у любого пода и имеет значение по умолчанию. А вот для джобы мы обязаны ее явно указать.
![[Pasted image 20241213110254.png]]
- Never - никогда не перезапускать. Ни в случае ошибки, ни в случае, если сами остановили приложение.
- Always - всегда перезапускать. Даже если сами руками остановили.
- OnFailure - перезапускать в случае ошибки.

Для джобы можем использовать либо Never, либо OnFailure. Выберем OnFailure и запустим джобу. После этого она выполнится и удалит записи, а потом завершится.
А если она не выполнилась, например, отключим БД, т.е. джоба не сможет подключиться к БД, то тогда из-за OnFailure будет перезапускаться под и снова попытка запустить джобу. Сколько раз будет перезапуск? Это параметр backoffLimit

А теперь поставим Never в restartPolicy. Тогда в таком случае, если joba не смогла выполниться, то старый под не перезапускается, а создается новый. Почему так происходит? Потому что, когда мы указываем Never, то за джобу отвечает кублет, который есть у каждой ноды. А когда указываем OnFailure, то за джобу отвечает сама джоба и поэтому перезапускается пода, в которой джоба попытался выполниться.

Вот так создаются новые поды, которые пытаются выполнить джобу в случае restartPolicy: Never:
![[Pasted image 20241213111500.png]]

backoffLimit - количество попыток выполнить(первая не считается, т.е. по факту будет 4 раза запущена)
![[Pasted image 20241213111654.png]]

completions - сколько раз должна выполниться джоба. Причем выполняются они последовательно. Т.е. создалась джоба, выполнилась, завершилась. Создалась новая джоба.
![[Pasted image 20241213111849.png]]

В том случае, если логика позволяет выполнять нам джобы параллельно, то есть параметр parallelism. Тогда стартанет сразу 5 подов джобы:
![[Pasted image 20241213112130.png]]

История о выполнении джобы остается в kubernetes dashboard.

Можем задавать дедлайн на выполнение джобы. Если за это время джобы не выполнились(т.е. тут должна не одно конкретная выполниться, а все то количество, которое указано в completions), то все, отменяем джобу.
![[Pasted image 20241213112420.png]]

ttlSecondsAfterFinished - сколько секунд джоба должна находиться в истории, после чего будет удалена, чтобы на захламлять dashboard.
![[Pasted image 20241213112655.png]]

### CronJob
Джобы, которые запускаются по таймеру, т.к. не круто, что мы должны кого-то заставлять заходить в kuberntes и запускать руками джобу для очистки БД.

Создание CronJob:
![[Pasted image 20241213112952.png]]
- schedule - период для запуска.
- concurrencyPolicy - 
- successfulJobsHistoryLimit - сколько успешных джобов хранить в истории.
- failedJobsHistoryLimit - сколько не успешных джобов хранить в истории.
- startingDeadlineSeconds - 

ConcurrencyPolicy - 
Есть джоба, которая без проблем работает.
![[Pasted image 20241213113317.png]]
Но, что если джоба выполняется долго - тогда джобы будут наслаиваться друг на друга, т.е. одновременно будет выполняться сразу несколько джоб. А что, если мы так не хотим? Это поведение настраивается ConcurrencyPolicy. По умолчанию оно равно allow, что разрешает параллельное выполнение нескольких джоб:
![[Pasted image 20241213113357.png]]

Forbid - запрещаем наслаивание и если джоба не успела выполниться к тому моменту, когда должна стартовать следующая, то следующая не стартует. Стартанет следующая джоба только в следующий период времени, который указан в schedule.
![[Pasted image 20241213113524.png]]

Replace - если к моменту начала следующей джобы прошлая не успела выполниться, то старая джоба отменяется и запускается новая.
![[Pasted image 20241213113654.png]]


startingDeadlineSeconds - насколько джоба может запаздать со своим стартом. Например, нода, на которой должна была запуститься джоба стала недоступна на некоторое время и джоба не может стартануть. Тогда мы можем указать, в течение какого периода джоба все еще может стартануть. Например, мы хотим, чтобы джоба запускалась каждый час и вот наступило 10:00, но нода в этот момент недоступна, тогда указав startindDeadlineSeconds: 180 мы говорим, что у джобы есть время до 10:03 чтобы все-таки стартануть.
![[Pasted image 20241213113753.png]]
А если она все-таки не успела стартануть в указанный тайминг, то следующий ее запуск будет по расписанию в 11 часов.

### Volumes
Допустим у нас есть кэш, который сохраняет себя в файлик. Мы хотим в кубернетес для поды выделить место, куда он сможет класть кэш и забирать кэш.
Для этого мы говорим, что по пути /urs/notes/cache/ - это папка внутри пода смонтирий в нее volume с именем notes-empty-dir.
![[Pasted image 20241213114415.png]]
Когда мы создаем volume с именем notes-empty-dir мы указываем emptyDir - это означает такой тип папки, которая связана напрямую с подом и живет только во время жизни пода. Создался под - хранилище создалось, под умер - хранилище умерло. У каждого пода своя папочка получается.

Мы можме нажатием этой кнопочки можем подключиться к поду и у нас будет bash.
![[Pasted image 20241213115016.png]]

С помощью этого можем зайти в ту папочку, в которой решили, что будем хранить кэш:
![[Pasted image 20241213115135.png]]

На самом деле вариантов хранилищ просто тьма и каждый из них нужно будет настраивать. Например, мы можем захотеть, чтобы хранилище существовало и без поды.
![[Pasted image 20241213115257.png]]

Но разработчик может не знать, как настроить какое-то конкретное хранилище и поэтому кубернетес решил решение этой проблемы. Он придумал заявки и постоянное хранилище.
![[Pasted image 20241213120900.png]]
Постоянное хранилище настраивается Dev-ops командой. А мы как разработчики только отправляем заявки, а потом уже средствами кубернетес подбирается хранилище, которое может удовлетворить заявке. 

![[Pasted image 20241213121221.png]]

![[Pasted image 20241213121243.png]]


### StatefulSet - для такой ситуации, когда в случае падения приложения мы хотим еще сохранить какое-то состояние

### HorizontalPodAutoscaler - блок, который может создавать или убивать поды в зависимости от того, под какой нагрузкой находится под.

https://gitlab.com/evgepishcin/k8s-presentation