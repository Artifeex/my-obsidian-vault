### Какой была жизнь до Kubernetes?
Мы хотим развернуть наш микросервис. Что нам для этого нужно? Нам нужна машина, на которой все это разворачивать. На эту машину нужно передать наш код, потом нам нужна БД, нужен файл для конфигурации. И все это нужно делать руками. Потом мы решили создать еще инстансы нашего микросервиса - а это снова повторяется тот процесс, когда нужно руками все настроить. Потом т.к. у нас несколько инстансов, то нам нужен какой-то балансировщик нагрузки, который будет распределять нагрузку между инстансами - вот уже и nginx появился. Ну и в конце концов получим такую картину:
![[Pasted image 20241210162101.png]]
И это мы создали тестовый контур, а нам нужно еще повторить все то же самое на product контуре.
![[Pasted image 20241210162629.png]]
### Kubernetes Cluster
Kubernetes Cluster - это как компьютерный кластер - такая система, которая состоит из нескольких компьютеров. Только такие компьютеры в Kubernetes кластере называются нодами.
![[Pasted image 20241210162801.png]]
Два вида Node:
- Worker -  на этих компьютерах будет запускаться приложение, которое мы хотим хостить на них.
- Master - нода, которая управляет жизненным циклом самого kubernetesa.

Как развернуть приложение внутри worker node?
Напрямую мы в нем не можем поднять наш контейнер. В Kubernetes есть дополнительная абстракция - pod. И вот внутри нее мы уже можем развернуть наш контейнер. У каждого пода внутри кластера есть IP адрес. Причем этот IP адрес именно внутри Kubernetes кластера. Извне если по этому IP адресу обратиться, то мы ничего не получим. А вот если внутри этого кластера какое-то приложение обратится по этому адресу, то оно обратится к поду. Обычно принято, что в одном поде - одно приложение. Но в некоторых случаях в одном поде может быть и два приложения. Пример такого случая: первое приложение может работать и писать логи, а второе приложение агрегирует эти логи и потом куда-то отсылает(например, в grafana есть alloy agent, который как раз занимается тем, что собирает логи и отправляет их в grafana loki - агрегирующий контейнер логов). И вот как раз alloy и приложение, которое генерит логи могут находиться внутри одной поды. Если обобщить, то можно развернуть сразу два контейнера в одной поде в том случае, если одно из приложений расширяет функционал другого.
![[Pasted image 20241210163250.png]]

### Добавим детализации в схему
![[Pasted image 20241210163927.png]]
На каждой Node стоит 
- Kubelet, который контролирует жизненный  ноды и самих приложений на этой ноде.
- k-proxy - отвечает за сетевое взаимодействие с API сервером на worker нодах.

### Как работать с Kubernetes?
Основная команда kubectl:
- kubectl get nodes - получить информацию по нодам, запущенным на компьютере.
  ![[Pasted image 20241210164832.png]]
- kubectl get pods - посмотреть поды.
  ![[Pasted image 20241210164919.png]]
  Видим, что тут вернуло что не нашло ресурсов в default namespace. Значит, есть namespaces. Это такие логические разделения. Под каждое приложение можем заводить свои неймспейсы.
- kubectl get namespaces - получить все неймспейсы. Все, что представлены ниже - это стандартные, которые создает для своих нужд кубер.
  ![[Pasted image 20241210165231.png]]
  - kubectl get pods -n <неймспейс>:
  ![[Pasted image 20241210165344.png]]

Работать с кубером мы можем не только через командную строку. Но еще и через dashboard:
![[Pasted image 20241210165514.png]]

### Как развернуть наше приложение в кубере?
Можем представить себе кубер как набор строительных блоков - каждый строительный блок - это и есть наше приложение. Строительные блоки бывают разные. Если привести аналогию с лего, то строительным блоком может быть деталька 5 на 8 или 10 на 5 и т.д. И вот из таких деталек строится весь кубер кластер.

Такие блоки описываются с помощью yml файла
![[Pasted image 20241210165829.png]]
- apiVersion - версия, которая будет использоваться для построения блока.
- kind - как раз тип строительного блока.
- metadata - информация, которая используется для того, чтобы мы могли различать наши приложения внутри кластера. Т.е. какая-то информация о том приложении, которое запущено внутри строительного блока
- spec - требуемое состояние объекта.

Опишем проект, который мы хотим развернуть:
![[Pasted image 20241210170107.png]]

Пусть есть микросервис notes, который имеет два метода. POST - для создания заметки(передается текст и attachment - это файл в кодировке base64, который можно прикрепить к заметки) и GET метод, с помощью которого можно получить заметки. Предполагаем пока, что БД нет. Что нужно сделать, чтобы развернуть такое приложение в кубере?
![[Pasted image 20241210170355.png]]

Сначала нам нужен pod, в котором уже будет работать наше контейнерезированное приложение.

Мы знаем, что для создания объектов в kubernetes нужно использовать yml файлы. Напишем такой:
![[Pasted image 20241210171424.png]]
Отлично, у нас есть описанный блок. Как нам его применить ?
apply - хотим применить такой строительный блок -f - файлик и путь до файлика:
![[Pasted image 20241210171527.png]]
Под создан. с помощью kubectl describe pods notes-pod можем получить информацию о нем:
![[Pasted image 20241210171635.png]]
Из интересного мы видим IP адрес, по которому могло бы обратиться другое приложение, развернутое в этом кластере. Также видим, что pod находится в дефолтном namespace.

Посмотреть логи - kubectl logs notes-pod
![[Pasted image 20241210171855.png]]

Либо можем посмотреть все через нашу dashboard.

Как удалить под?
kubectl delete pods notes-pod.

Если мы изменим наше приложени, потом его пересоберем и снова запустим, то на самом деле приложение в кубере не обновится, т.к. мы НЕ изменили в image контейнера внутри spec версию v1. А т.к. кубер это видит, то он просто использует кэш и не будет пересоздавать обновленный под. 

Как победить эту проблему? Самый очевидный вариант - изменить версию у image. Но это не всегда возможно. Второй вариант - использовать imagePullPolicy:

### imagePullPolicy
![[Pasted image 20241210172836.png]]
- IfNotPresent - образ скачивается в том случае, если он не сохранен локально. Это то, что произошло, когда мы изменили приложение, но изменения не отобразились внутри Kubernetes. Такое поведение по умолчанию. Kubernetes посмотрел, увидел, что у него локально есть такой образ и не стал его качать.
- Always - всегда будет скачивать из внешнего репозитория образы.
- Never - будет использовать только локальные образы. А если не найдет в кэше образ, то выбросит ошибку.
Добавим imagePolicy в наш под:
![[Pasted image 20241210173218.png]]

Хорошо, мы развернули. Но как теперь протестировать и обратиться к этому приложению? На самом деле при разработке есть команда, которая позволяет открыть временный доступ к поде из внешнего мира.

Вот так мы можем пробросить порт нашего приложение в открытый мир(так можно делать только при разработке, на проде так делать не надо :) )
kuberctl port-forward notes-pod 111111:8080
Теперь мы можем обратиться по такому порту 111111