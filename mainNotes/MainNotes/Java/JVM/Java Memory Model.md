https://habr.com/ru/articles/685518/
Код, который мы написали в программе и который реально выполнится - может отличаться. Инструкции могут быть переставлены компилятором(причем как JIT так и байткода) или выполниться процессором в другом порядке(процессор может построить по его мнению более оптимальный вариант). Т.е. перестановка происходит с целью выполнить код более оптимально с точки зрения стоимость выполнения процессорных инструкций.
Например: Операции чтения из памяти стоят дорого, поэтому эта оптимизация позволяет максимально эффективно утилизировать процессор, избежав простаивания, когда это чтение действительно понадобится


Но тогда непонятно, как написать программу, которая работала корректно.
Но существует гарантия as-if-serial - которая говорит, что как бы компилятор или процессор не выполнили код, который мы написали(даже в другом порядке) РЕЗУЛЬТАТ не должен измениться. Но проблема в том, что это гарантия работает только внутри одного потока. Т.е. если какой-то один поток ориентируется на то, что второй поток выполнит код в определенном порядке, то может возникнуть ошибка.

Например:
![[Pasted image 20241024225225.png]]
Если T1 выполнить в одном потоке, а Т2 в другом потоке, то можем получить один из 4-х выариантов значений для r1 и к2:
(0, 0) - в коде обоих потоков сначала была выполнена операция чтения r1 и r2. Т.е. х и y были равны 0, потом произошло чтение и в r1 и r2 записались 0, а потом только произошла инициализация. Или даже если перестановка не произошла, то могли не успеть синхронизироваться кэши в ядрах и из-за оптимизаций считалось бы значение из кэша, в котором х или y могли равняться 0.
(1, 0)
(0, 1)
(1, 1) - самый простой вариант, код выполнился в том порядке, в котором мы написали.

Мы поняли, что as-if-serial семантики недостаточно для многопоточных программ. Почему же не распространить as-if-serial гарантию на всю программу и ядра процессора? Ответ простой — это сильно ударило бы по производительности программ или процессора.

### Модель памяти
В общем, нам нужна поддержа со стороны спецификации языка. Поэтому более надежное решение — это создание так называемой _модели памяти_ (memory model), которая строго описывает какое выполнение программы является валидным. Модель памяти делает легальными многие оптимизации компилятора, JVM и процессора, но в то же время закрепляет условия, при которых программа будет вести себя корректно в многопоточной среде даже в присутствие оптимизаций. Таким образом, модель памяти:
- Разрешает выполнение различных оптимизаций компилятора, JVM или процессора
- Строго закрепляет условия, при которых программа считается правильно синхронизированной, и закрепляет поведение правильно синхронизированных программ
- Описывает отношение между высокоуровневым кодом и памятью
- Является trade-off между строгостью исполнения кода и возможными оптимизациями

Так вот, Java имеет свою модель памяти под названием **Java Memory Model** (JMM). По умолчанию JMM разрешает любые переупорядочивания и не гарантирует видимости изменений. Однако _при выполнении определенных условий_ нам гарантируется порядок действий, консистентный с порядком в коде, а также видимость всех изменений. Таким образом, JMM позволяет нам писать программы, которые будут полностью корректно работать среди множества различных имплементаций JDK и микро-архитектур процессоров, в то же время сохраняя преимущества оптимизаций.

Т.е. в JMM описаны условия, которые мы должны выполнить нашим кодом, чтобы РЕЗУЛЬТАТ выполнения был таким, как мы задумали, даже если при выполнении код реально переставится.

### Memory Ordering
**Memory Ordering** описывает _наблюдаемый программой_ порядок, в котором происходят действия с памятью.
Смотрите: со стороны программы есть только действия записи/чтения и их порядок в коде. Также со стороны программы кажется, что мы имеем единую общую память, записи в которую становятся сразу видны другим тредам. Программа не подозревает ни о каких instruction scheduling reordering/out-of-order execution/caching/register allocation и прочих оптимизациях под капотом. Если по какой-то причине мы наблюдаем результат, не консистентный с порядком в программе, то со стороны программы (высокоуровнево) это выглядит так, что действия c памятью просто были переупорядочены. Другими словами, _порядок взаимодействия с памятью (memory order) может отличаться от порядка действий в коде (program order)_.

Т.е. Memory Ordering - это порядок реального взаимодействия с памятью под капотом, т.е. в каком порядке происходило чтение и запись. И в программе мы можем написать работу с памятью в одном порядке, а под капотом она может выполниться в другом. 

Ваша программа отрабатывает в одном из порядков, валидных с точки зрения JMM. Таким образом, если программа не правильно синхронизирована, не стоит удивляться некорретному результату выполнения. Ведь важно то, валиден ли результат выполнения с точки зрения модели памяти, а не то, валиден он или нет для вас как пользователя.

LOAD - чтение
STORE - запись(сохранение)

В свою очередь, _Memory Reordering_ — это высокоуровневое понятие, которое абстрагирует и обобщает низкоуровневые проблемы, которые мы рассматривали выше. Всего существует 4 типа memory reordering:
1. _LoadLoad_: переупорядочивание чтений с другими чтениями. Например, действия `r1, r2` могут выполниться в порядке `r2, r1`
2. _LoadStore_: переупорядочивание чтений с записями, идущими позже в порядке программы. Например, действия `r, w` могут выполниться в порядке `w, r`
3. _StoreStore_: переупорядочивание записей с другими записями. Например, действия `w1, w2` могут выполниться в порядке `w2, w1`
4. _StoreLoad_: переупорядочивание записей с чтениями, идущими позже в порядке программы. Например, действия `w, r` могут выполниться в порядке `r, w`

И в зависимости от того, какие Memory Reordering разрешены в модели памяти, сами модели памяти разделяются на
1. _Sequential Consistency_: запрещены все переупорядочивания
2. _Relaxed Consistency_: разрешены некоторые переупорядочивания
3. _Weak Consistency_: разрешены все переупорядочивания

Модель памяти существует как на уровне языка, так и на уровне процессора, но они не связаны напрямую. Модель языка может предоставлять как более слабые, так и более строгие гарантии, чем модель процессора.

В частности, как уже было сказано выше, Java Memory Model не дает никаких гарантий, пока не использованы необходимые примитивы синхронизации. И напротив, посмотрите на главу Memory Ordering из [Intel Software Developer’s Manual](https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-system-programming-manual-325384.pdf#G13.14501):

> - Reads are not reordered with other reads [запрещает LoadLoad reordering]
> - Writes are not reordered with older reads [запрещает LoadStore reordering]
> - Writes to memory are not reordered with other writes [запрещает StoreStore reordering]
> - Reads may be reordered with older writes to different locations but not with older writes to the same location [разрешает StoreLoad reordering]
> 
>   

Как видите, Intel разрешает только `StoreLoad` переупорядочивания, а все остальные запрещены. Да, модель памяти x86 достаточно строга, но есть и намного более слабые модели памяти процессоров — например, ARM разрешает все переупорядочивания.

Однако даже если вы пишите программу под x86, вам все равно необходимо считаться с более слабой Java Memory Model, так как последняя разрешает все переупорядочивания на уровне компилятора. _Модель памяти языка — прежде всего._

###   Memory Ordering vs Instructions Ordering
Еще раз закрепим: Memory Ordering и Instructions Ordering — это не одно и то же. Инструкции могут переупорядочиваться под капотом как угодно, но их _memory effect_ должен подчиняться некоторым Memory Ordering правилам, которые гарантируются (или не гарантируются) Memory Model. Наконец, _memory ordering_ — это высокоуровневое понятие, созданное для простоты понимания работы с памятью.

Т.е. инструкции могут переставляться под капотом, НОО, главное, чтобы они удовлетворяли Memory Ordering правилам, т.е. если наша модель памяти запрещает LOADSTORE, то будут разрешены только такие перестановки инструкций, которые не повлекут за собой перестановку чтения и записи.

## Введение: Sequential Consistency
**Sequential Consistency Model (SC)** — это очень строгая модель памяти, которая гарантирует отсутствие переупорядочиваний.

Интуитивно SC можно понять очень просто: возьмите действия тредов, как они идут в порядке программы, и просто выполните их последовательно, возможно переключаясь между тредами.

Т.е. в случае Sequential Consistency невозможно получить (0, 0) в примере выше, т.к. в такой модели памяти запрещено LOADSTORE.

Отлично, все это звучит здорово, но как же нам получить такую модель памяти? Ведь как мы уже поняли, JMM — это слабая модель памяти, которая не гарантирует консистентного порядка памяти.

Однако я уже упоминал выше, что при соблюдении некоторых условий наша программа будет считаться правильно синхронизированной и всегда работать корректно. Так вот, Java Memory Model — это **Sequential Consistency-Data Race Free (SC-DRF)** модель: нам предоставляется sequential consistency, но только в том случае, если мы избавимся от всех _data race_ в программе — про это мы еще поговорим далее.

Data Race - это когда мы в многопоточной программе обращаемся к разделяемой общей памяти из нескольких потоков(пишем, читаем) без использования каких-либо синхронизаций.

У Sequntial Consistency  есть набор возможных результатов выполнения кода. Например, для примера выше возможны варианты (1,1), (0,1), (1,0) и тогда будут считаться валидными любые переставноки, результат которых будет таким, как указано в перечислении выше. Т.е. результат (0, 0) - запрещен, а, значит, что перестановка инструкций для достижения такого результата невозможна.

Таким образом, представить себе работу SC модели памяти можно следующим образом:
1. Модель памяти "анализирует" оригинальную программу и исходя из порядка действий в программе "просчитывает" сет всех возможных sequentially consistent порядков и их результатов
2. С учетом получившегося сета результатов модель памяти разрешает делать любые оптимизации, пока они приводят к одному из sequentially consistent результатов, и запрещает делать такие оптимизации, которые могут привести к sequentially inconsistent результату

So, here's the deal: вы избавляетесь от всех _data race_ в коде и получаете программу, результат которой будет всегда не отличим от одного из sequentially consistent порядков, а разработчики JMM получают возможность делать любые оптимизации под капотом, пока они приводят к валидному результату.

Чтобы добиться SC нужно избавиться от всех datarace в программе. Т.е. если потоки не конфликтуют, то никаких проблем не будем и мы будем получать один из результатов, допустимым в SC.

Избавиться от гонок можно двумя способами:
1. Связать все действия с shared данными в synchronization order
2. Связать все действия с shared данными в happens-before order

## JMM: Synchronization Order
Как мы уже знаем, JMM — это слабая модель памяти, которая не соблюдает порядок программы. Поэтому модель должна нам предоставить специальные примитивы, при использовании которых гарантировался бы консистентный порядок.

И такое решение действительно есть: JMM предоставляет специальные примитивы под названием _Synchronization Actions (SA)_. Для таких действий образуется полный порядок под названием _Synchronization Order (SO)_, в котором:
1. Порядок действий _консистентен с порядком программы
2. Каждое чтение всегда видит предыдущую запись

Нас интересуют следующие synchronization actions:
1. Запись и чтение `volatile` переменной
2. Взятие и освобождение монитора

Т.е. если у нас в коде происходит работа с volatile переменными, то чтение и запись в такие переменные будет строго в том порядке, в котором мы написали в программе, т.е. невозможна ситуация STORELOAD и LOADSTORE при использовании volatile(имеется в виду, что нужно еще обнаружить изменение(publish) volatile переменной и тогда код, который шел до изменения volatile переменной будет виден). 
## JMM: Happens-before: теория
**Happens-before** определяется как отношение между двумя действиями:
1. Пусть есть поток `T1` и поток `T2` (необязательно отличающийся от потока `T1`) и действия `x` и `y`, выполняемые в потоках `T1` и `T2` соответственно
2. Если `x` happens-before `y`, то во время выполнения `y` треду `T2` будут видны все изменения, выполняемые в `x` тредом `T1`

Т.е. happend-before говорит о том, что если какой-то thread выполняет действие(y) после действия(x) из другого треда, то при выполнении действия(y) будут видны все изменения действия(х).

_Happens-before_ — это еще один способ, с помощью которого мы добьемся sequential consistency. Смотрите:
1. Если мы свяжем conflicting доступ к shared переменной с помощью happens-before, то избавимся от data race
2. Если мы избавимся от data race, то получим sequential consistency
3. Если мы получим sequential consistency, то наша программа всегда будет выдавать консистентный с порядком в программе результат

Давайте сразу проясним один момент: нет, happens-before не означает, что инструкции под капотом будут действительно выполняться в таком порядке. Если переупорядочивание инструкций все равно приводит к консистентному результату, то такое переупорядочивание инструкций не запрещено

Далее мы рассмотрим все действия, для которых JMM гарантирует отношение happens-before.

Если действие `x` идет перед `y` в коде программы и эти действия происходят в одном и том же треде, то `x` _happens-before_ `y`:

Это формальное определение as-if-serial семантики, которую я уже упоминал в начале статьи: если действие `A` идет перед действием `B` в порядке программы (program order), то `B` гарантированно увидит все изменения, которые должны быть сделаны в `A`

|Thread 0|
|---|
|x = 1|
|r1 = y|
Для этого треда гарантируется, что `write(x, 1)` happens-before `read(y)`. Однако эти действия никак не связаны: запись в `x` не влияет на чтение `y`. Другими словами, на чтении `y` нам не нужно видеть изменений, сделанных при записи в `x`. Поэтому даже если инструкции будут переупорядочены, то happens-before между этими действиями не будет нарушено.

|Thread 0'|
|---|
|x = 1|
|y = x + 1|
В такой программе действия связаны — на записи в `y` нам необходимо наблюдать запись в `x`. Именно в данном случае благодаря happens-before мы увидим результат записи в `x`

### Happens-Before Monitor lock

Освобождение монитора _happens-before_ каждый последующий захват того же самого монитора.
### Happens-Before Volatile
Запись в `volatile` переменную _happens-before_ каждое последующее чтение той же самой переменной.

### Final thread action
Финальное действие в треде T1 _happens-before_ любое действие в треде T2, которое обнаруживает, что тред T1 завершен.
- Финальное действие в `T1` _happens-before_ завершение вызова `T1.join()` в `T2`
- Финальное действие в `T1` _happens-before_ завершение вызова `T1.isAlive()` в `T2` (если вызов возвращает `false`)

### Happens-before Thread start action
Действие запуска треда (`Thread.start()`) _happens-before_ первое действие в этом треде.

### Thread interrupt action
Если тред `T1` прерывает тред `T2`, то интеррапт _happens-before_ обнаружение интеррапта. Обнаружить интеррапт можно или по исключению `InterruptedException`, или с помощью вызова `Thread.interrupted`/`Thread.isInterrupted`.

### Default initialization
Дефолтная инициализация (`0`, `false` или `null`) при создании переменной _happens-before_ первое действие в каждом треде.

### Happens-before transitivity
Важно отметить, что отношение _happens-before_ является _транзитивным_. То есть, если `hb(x,y)` и `hb(y,z)`, _то_ `hb(x,z)`.

Это приводит нас к одному очень важному и интересному наблюдению. Мы знаем, что два последовательных действия в одном и том же треде связаны с помощью _happens-before_ (same thread actions). Тогда если действие `A` в одном треде связано отношением _happens-before_ с действием `B` в другом треде, то благодаря транзитивности второму треду _во время и после выполнения действия `B`_ будут видны все изменения, сделанные первым тредом _до и во время выполнения действия `A`_.

Еще раз: если есть последовательные действия `[A1, A2]` в первом треде, последовательные действия `[B1, B2]` во втором треде, и `hb(A2, B1)`, _то_ `hb(A1, B1)`, `hb(A1, B2)` и `hb(A2, B2)`

Вот как мы можем применить это знание:

- Не только освобождение монитора, но и все действия, идущие в порядке программы до освобождения, будут видны другому треду после захвата этого же монитора
- Не только запись в volatile поле, но и все действия, идущие в порядке программы до записи, будут видны другому треду после чтения этого же поля
- Не только финальное действие, но и все предыдущие действия треда T1 будут видны другому треду после завершения `T1.join()`
- Не только первое действие в треде, но и все последующие действия увидят дефолтную инициализацию переменной
- … не будем продолжать — идея понятна

  

Давайте с учетом этой информации запишем более полное определение _happens-before_:

  

1. Пусть есть поток `T1` и поток `T2` (необязательно отличающийся от потока `T1`) и действия `x` и `y`, выполняющиеся в потоках `T1` и `T2` соответственно
2. Если `x` happens-before `y`, то треду `T2` во время выполнения `y` и всех действий, идущих в порядке программы позже, будут видны все изменения, выполняемые тредом `T1` в `x` и всех действиях, идущих в порядке программе ранее

## JMM: Happens-before: практика

Мы уже на полпути к написанию корректных многопоточных программ — теперь осталось только применить полученные значения на практике. За основу для дальнейших примеров возьмем следующую нерабочую программу:
![[Pasted image 20241025104030.png]]

Можно подумать, что если мы прочитали значение `true` на `R1`, то прочитаем и значение `5` на `R2`, так как в порядке программы запись в `x` идет перед записью в `initialized`. Но на самом деле мы можем наблюдать значение по умолчанию (`0`) при чтении `x` по следующим причинам:

1. _Instructions reordering (1/2)_ — записи W1 и W2 были переставлены местами
2. _Instructions reordering (2/2)_ — чтения R1 и R2 были переставлены местами
3. _Visibility_ — запись в `x` не пропагирована другим ядрам на момент чтения

С точки зрения программы мы говорим, что произошли `StoreStore` или `LoadLoad` переупорядочивания. Это ожидаемо, ведь мы имеем две гонки: при доступе к `x` и `initialized`. А соответственно, нам не гарантируются только sequentially consistent выполнения, ведь такие переупорядочивания валидны с точки зрения JMM при наличии гонок.

Далее мы доведем эту программу до полной корректности, используя happens-before. Нашей целью будет связать доступ к этим переменным с помощью happens-before, чтобы избавиться от гонок и добиться только sequentially consistent выполнений.

### Monitor lock
[Monitor lock](https://docs.oracle.com/javase/tutorial/essential/concurrency/locksync.html) не только предоставляет happens-before между освобождением и взятием лока, но также является и [мьютексом](https://ru.wikipedia.org/wiki/%D0%9C%D1%8C%D1%8E%D1%82%D0%B5%D0%BA%D1%81), который позволяет обеспечить эксклюзивный доступ к критической секции. Каждый объект в Java содержит внутри себя такой лок, но его нельзя использовать напрямую — чтобы воспользоваться им, необходимо применить keyword `synchronized` (отсюда и альтернативное название _intrinsic lock_).
![[Pasted image 20241025104044.png]]
В данном примере мы используем монитор объекта `lock`, свойство happens-before которого гарантирует следующее: после получения монитора `reader` увидит все изменения, которые идут в порядке программы перед освобождением монитора в треде `writer`. Или наоборот, если счанала монитор захватил reader, то он будет работать с дефолтными значениями, т.к. в данном случае reader happens before writer.

И теперь у нас только 2 варианта выполнения данного кода, мы либо получим r1  = true, r2 = 5. Либо r1=false, r2=(ничему, поскольку мы не попадем в секцию, где r2 создается)

### Volatile

_Volatile_ предоставляет happens-before гарантию между записью и чтением из `volatile` переменной. Семантика volatile отличается от монитора только тем, что не предоставляет эксклюзивный доступ к критической секции.

Вот так с помощью `volatile` мы исправляем ту же самую программу:
![[Pasted image 20241025104431.png]]
И таким образом, если мы увидим в initialized значение true, то, значит, и увидим х=5. 
```
write(x, 5) -> write(initialized, true) -> read(initialized):true -> read(x):5 // (initialized, x) = (true, 5)
write(x, 5) -> read(initialized):false -> write(initialized, true) // (initialized, x) = (false, _)
read(initialized):false -> write(x, 5) -> write(initialized, true) // (initialized, x) = (false, _)
```

## Safe Publication/RA semantics
Наверняка вы заметили, что в обоих примерах прослеживается некая идиома: делаем все необходимые изменения до некоторого синхронизирующего треды действия `A` (запись в `volatile` переменную, освобождение лока), а читаем эти изменения после другого синхронизирующего действия `B` (чтение `volatile` переменной, взятие лока) — это называется _[acquire/release семантика](https://preshing.com/20120913/acquire-and-release-semantics/)_ или _Safe Publication_ (безопасная публикация). Наверняка, многие из вас слышали последнее понятие.

Например, если мы имеем действия `[W1, W2, W3, RELEASE]`, то `[W1, W2, W3]` могут быть переупорядочены под капотом как угодно, но они всегда будут выполнены до `RELEASE` действия.

## Happens-before is about actions

  

После того как мы рассмотрели работу happens-before на практике, я бы хотел подробнее остановиться на одном важном моменте. Может кому-то все далее написанное покажется очевидным, но разобраться не помешает.

  

Вы уже достаточно много раз увидели слово "действие" (action) пока читали раздел про happens-before, но скорее всего смысл его не до конца очевиден. Так вот, под "действием" спека имеет в виду результат выполнения выражения в рантайме, а не само статическое выражение в коде (statement). Например, `boolean r1 = initialized;` это всего лишь выражение в программе, но оно может иметь результат: чтение `true` или `false`. Это и есть действие, которое имеет определенный результат во время выполнения. Действия следует рассматривать свободно и абстрактно от различных переупорядочиваний под капотом: просто смотрите на порядок выражений в коде программы, но думайте о том, какой результат может иметь выражение.

  

Теперь следует сказать, что happens-before (и все остальные порядки в JMM) — это именно о _действиях_ (actions), которые имеют какой-то результат, а не об абстрактных выражениях в программе.

  

Давайте еще раз взглянем на определение happens-before для треда в изоляции:

  

> If `x` and `y` are _actions_ of the same thread and `x` comes before `y` in program order, then `hb(x, y)`.

Как видите, здесь говорится именно о _действиях_ (actions): два любых действия в одном и том же треде связаны happens-before, если их соответствующие выражения идут последовательно в порядке программы. Приведу отдельный пример: happens-before существует не между выражениями `x = i` и `int r1 = x`, а между действиями записи `write(x, 5)` и чтением `read(x)`, которое гарантированно обнаружит `5` благодаря установке hb между ними (допустим, что при выполнении `i` имеет значение `5`). Здесь все просто.

  

А вот в случае `volatile` все немного интереснее. Вот определение hb для volatile:

  

> A write to a volatile variable `v` happens-before all _subsequent_ reads of `v` by any thread

Обратите внимание на слово _"subsequent"_ — это очень важная деталь, которая различает действия и выражения. Определение говорит, что чтение должно _обнаружить_ эту запись, чтобы между записью и чтением `volatile` переменной было установлено happens-before отношение. То есть, здесь подразумевается некоторый результат выполнения — это и есть "действие".

  

Именно поэтому даже в случае использования `volatile` _все еще необходимо_ делать условие `if (initialized)`, ведь только при обнаружении записи устанавливается отношение `hb` между двумя тредами. То есть, определение happens-before для `volatile` не говорит, что в рантайме чтение всегда увидит `true`, ведь это зависит от шедулера JVM/ОСи и времени пропагации записи другим тредам (eventual visibility). Определение говорит, что _если_ запись была обнаружена, то будет установлено отношение hb между тредами. Аналогично следует рассуждать и о мониторе: необходимо обнаружить освобождение монитора, чтобы было установлено hb между тредами.

Подводя итог, этим разделом я хотел сказать следующее:
1. Happens-before — это о действиях, которые имеют какой-то результат, а не об абстрактных выражениях в программе. Следите внимательно за тем, при каких условиях устанавливается hb, и анализируйте свой случай
2. Для synchronization actions отношение happens-before устанавливается только при обнаружении определенного эффекта памяти. Например, для `volatile` переменной hb устанавливается только после обнаружения записи, а для монитора после обнаружения его освобождения
3. Для действий в одном и том же треде happens-before устанавливается всегда




Т.е. важно понимать, что для установления связи happens-before нужно, чтобы мы сначала обнаружили и получили результат синхронизирующего действия, т.е. в случае volatile мы должны через if получить подтверждение тому, что код до volatile выполнился, а, значит, мы можем пользоваться этим, т.к. установилась связь happens-before. И аналогично с монитором, в котором только после захвата монитора мы можем делать предположения о том, что какой-то код уже выполнился.
## Cache Coherence
В самом начале статьи я уже затрагивал тему Cache Coherence, а теперь разберемся в ней подробнее.
Перед тем как идти дальше, рассмотрим устройство кэша на базовом уровне:
1. Процессор никогда не работает с памятью напрямую — все операции чтения и записи проходят через кэш. Когда процессор хочет загрузить значение из памяти, то он обращается в кэш. Если значения там нет, то кэш сам ответственнен за выгрузку значения из памяти с последующим сохранением в кэше. Когда процессор хочет записать значение в память, то он записывает значение в кэш, который в свою очередь ответственен за сброс значения в память
2. Кэш состоит из множества "линий" (cache line) фиксированного размера, в которые кладутся значения из памяти. Размер линий варьируется от 16 до 256 байт в зависимости от архитектуры процессора. Кэш сам знает, как мапить адрес линии кэша в адрес памяти
3. Кэш имеет фиксированный размер, поэтому может хранить ограниченное количество записей. Например, если размер кэша 64 KB, а размер линии кэша 64 байт, то всего кэш может содержать 1024 линии. Поэтому, если при выгрузке нового значения места в кэше не хватает, то из кэша вымещается одно из значений
4. Большинство современных архитектур процессоров имеют [несколько уровней кэша](https://en.wikipedia.org/wiki/Cache_hierarchy): обычно это L1, L2, и L3. Верхние уровни кэша (L1, L2) являются локальными — каждое ядро процессора имеет собственный, отдельный от других ядер кэш. Кэш на самом нижнем уровне (L3) является общим и шарится между всеми ядрами  
    1. Доступ к каждому последующему уровню кэша стоит дороже, чем к предыдущему. Например, доступ к L1 может стоить 3 цикла, L2 — 12 циклов, а к L3 — 38 циклов
    2. Каждый последующий кэш имеет больший размер, чем предыдущий. Например, L1 может иметь размер 80 KB, L2 — 1.25 MB, а L3 — 24 MB

Из-за того, что ядра имеют собственный локальный кэш, возникает потенциальная проблема чтения неактуальных значений. Например, пусть два ядра прочитали одно и то же значение из памяти и сохранили в свой локальный кэш. Затем первое ядро записывает новое значение в свой локальный кэш, но другое ядро не видит этого изменения и продолжает читать устаревшее значение. Как итог, данные среди локальных кэшей не консистентны. Если бы в процессоре существовал только общий кэш, то проблемы чтения неактуальных значений просто не существовало бы: так как все записи и чтения проходят через кэш, а не идут напрямую в память, то общий кэш по сути был бы master копией памяти,

**[Cache Coherence](https://en.wikipedia.org/wiki/Cache_coherence)** (когерентность кэша) — это механизм процессора, гарантирующий, что любое ядро всегда читает самое актуальное значение из кэша. Данным механизмом обладают многие современные архитектуры процессоров в той или иной имплементации.

Как видите, в половине случаев тред завис навсегда. Это произошло по той причине, что компилятор оптимизировал цикл `while (!ready)` в `while(true)`. Компилятор свободен это делать, так как переменная не изменяется ни до, ни внутри цикла, а также не связана отношением happens-before с действиями в других тредах.

  Исправить этот пример можно пометив переменную как [volatile](https://github.com/openjdk/jcstress/blob/83365e01e6606f8368a74b3e5503361f51074cde/jcstress-samples/src/main/java/org/openjdk/jcstress/samples/jmm/basic/BasicJMM_04_Progress.java#L74) или работая с переменной под [монитором](https://github.com/openjdk/jcstress/blob/83365e01e6606f8368a74b3e5503361f51074cde/jcstress-samples/src/main/java/org/openjdk/jcstress/samples/jmm/basic/BasicJMM_04_Progress.java#L147) — только в этом случае нам гарантируется eventual visibility изменений.

  Таким образом, пока мы работаем с обычными записями и чтениями, не связанными отношением happens-before, нам не гарантируется видимость изменений, сделанных из других тредов.

## Memory Barriers

Процессор может переупорядочивать выполняемые им инструкции, даже если на уровне компилятора мы обеспечили необходимый порядок. Хотя процессор делает только такие переупорядочивания, которые не меняют итогового результата, но это гарантируется только для единственного ядра в изоляции, поэтому переупорядочивание может повлиять на другие ядра. Более того, все еще существует проблема видимости изменений, которую мы обсудили выше. Именно поэтому JMM ответственна и за синхронизацию на уровне процессора.

Для решения этих проблем Java использует готовые низкоуровневые механизмы синхронизации под названием "memory barrier", предоставляемые самим процессором. Задача барьеров памяти — запретить (memory) переупорядочивания, которые обычно разрешены моделью памяти процессора. Таким образом, точно так же как мы используем примитивы синхронизации `volatile`/`synchronized` в высокоуровневом коде, сама Java под капотом тоже использует похожие низкоуровневые примитивы синхронизации.

## Как JMM обеспечивает консистентный memory order: подводим итоги

Итак, давайте резюмируем, что делает JMM на каждом из уровней, чтобы правильно синхронизированная программа не имела переупорядочиваний. Happens-before — это конечно хорошо, но это всего лишь абстракция. А вот на нижнем уровне компилятора и хардвара JMM на самом деле делает следующее:

1. Compiler memory ordering  
    1. Уровень компилятора байткода (`javac`)  
        - Обеспечивает такой порядок сгенерированных bytecode инструкций, который будет консистентен с порядком действий в коде
    2. Уровень компилятора машинного кода (`HotSpot JIT Compiler C1/C2`)  
        - Обеспечивает такой порядок сгенерированных машинных инструкций, который будет консистентен с порядком действий в коде
2. CPU memory ordering  
    - Расставляет барьеры памяти в нужных местах так, чтобы memory ordering машинных инструкций был консистентен с порядком действий в коде

Первые два уровня зависят полностью от самой Java — именна она имплементирует гарантию порядка. Уровень процессора же зависит не только от Java, но и от самого процессора, который предоставляет и имплементирует барьеры памяти.

## JMM: Atomicity

Важная часть JMM, которую я не упоминал ранее, это атомарность некоторых базовых действий. А именно:

- Чтения и записи _reference переменных_ (ссылок) являются атомарными
- Чтения и записи _примитивов_ (кроме long/double) являются атомарными
- Чтения и записи _long/double переменных_, помеченных как `volatile`, являются атомарными

Что же нам дают эти свойства в многопоточной среде? Нам гарантируется, что при shared чтении переменной мы увидим или значение по умолчанию (`0`, `false`, `null`), или полное консистентное значение, но не половинное значение. Даже если в переменную пишут одновременно несколько тредов, то мы увидим результат записи одного из них, но не будет такой ситуации, что чтение увидит первую половину битов из одной записи, а вторую половину из другой записи.

Но почему мы вообще могли бы прочитать половинное значение? Дело в том, что некоторые типы в языке имеют размер (в битах) больший, чем длина [машинного слова](https://en.wikipedia.org/wiki/Word_(computer_architecture)) процессора. Например, 32-х битный процессор оперирует словами по 32 бита, но тип long/double содержит 64 бита. Соответственно, языку требуется совершить 2 записи по 32 бит, чтобы полностью записать значение.


JMM дает очень полезную гарантию порядка и видимости записей для `final` полей: если ссылка на создаваемый объект не утекла во время работы конструктора (так, что ее мог увидеть другой тред), то все остальные треды, которые увидели non-null ссылку на этот объект, _гарантированно прочитают актуальные значения всех внутренних `final` полей объекта_ вне зависимости от того, была гонка при чтении ссылки или нет.

Семантика `final` полей напрямую касается иммутабельных объектов. Известно, что такие объекты можно безопасно шарить между тредами. Но без данной гарантии JMM это было бы не правдой, ведь проблема переупорядочивания все еще никуда не делась. Именно благодаря тому, что JMM автоматически берет на себя задачу по синхронизации `final` полей, мы имеем возможность корректно шарить иммутабельные объекты без использования примитивов синхронизации.