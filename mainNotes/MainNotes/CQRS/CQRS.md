### Что такое микросервисы?
![[Pasted image 20241115115220.png]]![[Pasted image 20241115115346.png]]
Spring Cloud - это environment, который предоставляет множество услуг для микросервисов, написанных на SpringBoot.
### Microservice vs Monolit
![[Pasted image 20241115115521.png]]
Монолит - это одно большое приложение, которое содержит в себе контроллеры, каждый из которых отвечает за какую-то функциональность. И если мы захотим изменить в каком-то контроллере код, то придется ребилдить все приложение, а это для очень больших монолитов может занимать приличное время.
В микросервисах же у нас есть маленькие веб-сервисы(просто приложенька отдельная), которые отвечают за свой функционал, как раньше это делали контроллеры. И плюсом является то, что они меньше, поэтому в них проще разобраться, каждый микросервис может быть написан на различных технологиях, в то время как монолит обязан быть написан на одном языке. 

Но сложностью в случае микросервисов является общение между компонентами. В монолите мы просто заимпортили один сервис в другой сервис и у нас все хорошо. 
Микросервисы чаще всего общаются по HTTP.
![[Pasted image 20241115120054.png]]
На диаграмме выше мы видим, что у нас есть клиенты, которые шлют HTTP запросы для работы с нашими сервисами. Красный квадрат - это как раз SpringCloud. В нем есть микросервис API Gateway - просто снова приложенька на Spring Boot. И другие составляющие - такж являеются просто приложениями. А также у нас есть множество микросервисов, которые уже общаются между собой по HTTP.
![[Pasted image 20241115120443.png]]
Еще важной составляющей для микросервисов является то, что мы можно отдельно их редеплоить и они могут жить независимо от других микросервисов.

Представим, что у нас есть монолит:
![[Pasted image 20241115120639.png]]
И он рос, рос и мы решили распилить его на микросервисы.
Когда мы создаем микросервисы, то у нас теперь для каждого микросервиса своя БД. Этот паттерн называется database per class. И другие микросервисы не могут лазить в БД нашего микросервиса.
![[Pasted image 20241115120806.png]]
Если нагрузка на какой-то микросервис растет, то мы можем запустить на одном hoste, на котоом работает микросервис сразу несколько инстансов этого микросервиса - такой паттерн называется multiple instances per host. И мы можем запускать сколько угодно микросервисов Products на одном сервере, поскольку у каждого из них свой port и поэтому они не конфликтуют.
![[Pasted image 20241115121015.png]]

Но у нас появляется проблема. Когда был монолит, то из-за того, что он был запущен в одном instance, то мы на клиенте знали его port и тогда понятно, куда отправлять наши HTTP запросы. Но теперь у нас несколько микросервисов, каждый занимается какими-то своими делами, так еще и есть возможность запуска сразу несколько одинаковых микросервисов(products), причем при таком запуске порты генерируется динамически, т.е. порт микросервиса мы можем узнать только при старте нашего микросервиса. 

Сначала решим проблему с тем, что клиент не знает порт. Эту проблему решает API Gateway - приложение, которое работает на известном порту и к нему и делает запрос клиент. Это приложение знает о наших микросервисах и их портах и будет перенаправлять запросы на соотвествующий микросервис. Но откуда оно их знает? Ведь мы сказали, что порты динамические и известны только при старте приложения. Для этого существует Eureka Service Discovery - еще одна программка, которую можно считать адресной книжкой, в которой хранится информация о микросервисах. Когда микросервис запускается, то он регистрируется в Eureka Service, чтобы сообщить как раз свой порт. И тогда API Gateway может спросить у Eureka порт нужного микросервиса для отправки. 

Разберемся теперь с вопросом о нескольких инстансах одного микросервиса. Мы их создали из-за повышенной нагрузки и теперь нам нужно распределить запросы по ним. Поэтому появляется Load Balancer, который и будет заниматься распределением нагрузки. Он может быть как встроен в API Gateway, так и быть отдельным объектом, с который API Gateway будет работать.
![[Pasted image 20241115121545.png]]

Решим еще одну проблему. У каждого микросервиса есть свой конфигурационный файлик, в котором могут находиться различные настройки. Поэтому нам бы хотелось иметь какой-то централизованное место, где мы могли бы настраивать эти конфигурации. Этим центральным местом будет Config Server, который позволит нам изменять какие-то конфигурации на лету, т.е. не придется отстанавливать микросервис для каких-то изменений
![[Pasted image 20241115133251.png]]

Мы рассмотрели 4 составляющие микросервисной архитектуры:
![[Pasted image 20241115133531.png]]
Но есть и множество других.

### Event-Driven microservice
Микросервисы могут общаться по обычному HTTP. Делаю request и получая Response. Этот подход подходит под множество usecases, но не всегда.
![[Pasted image 20241115133846.png]]

Но представим ситуацию, что есть микросервис А и он хочет доставить одно и то же сообщение сразу множеству микросервисов. В таком случае нам уже не поможет то общение, которое мы описали выше. Т.е. да, мы бы могли с каждым микросервисом так обменяться, но это долго, поскольку если микросервисов 10-ки, то это 10-ки отправок одних и тех же сообщений и ожидания ответов, а также могут добавляться новые микросервисы, которые также будут хотеть получать сообщения.

Поэтому решением является Event-Driven подход, в котором микросервис А отправляет сообщения в брокер сообщений, а другие читают из этого брокера. Такая модель еще называется Producer/Consumer или Publisher/Subscriber. 
![[Pasted image 20241115134314.png]]

Producer может отправлять различные типы сообщений или events, а consumer получает эти events. И как раз потому что producer publish event или message такая архитектура общения и называется event driver или message driven.

Также стоит заметить, что Event-Driven architecture является асинхронной! Т.е. Когда в микросервис А приходит какая-то команда, которую ему нужно выполнить, то он publish event в message broker и не дожидается того, когда этот event и главное КЕМ этот event будет обработан. Он свое дело сделал, принял команду и создал event, который уже другие должны обработать. И микросервис А не ожидает какого-то респонса от subsriber-ов. Он сразу после того, как запушил event отправляет response для того запроса, который к нему пришел. 
![[Pasted image 20241115135207.png]]

Причем еще стоит заметить, что если какой-то из consumers отвалится, то ничего не поломается, т.к. брокер, в который отправили event продолжит хранить сообщение у себя. И потом, когда consumer микросервис очнется, то он сможет без проблем прочитать сообщения из брокера.

В случае же не event driven подхода
![[Pasted image 20241115135713.png]]
Если микросервис B помрет, то микросервис А ничего сделать не может, ему нужно дождаться ответа.

### Transactions in microservice
В случае монолита с транзакциями работать довольно просто. Мы запустили транзакцию, выполняем внутри нее какие-то шаги и потом заканчиваем транзакцию. И если в течение транзакции произошла какая-то ошибка, то мы без проблем делаем rollback всех действий.
![[Pasted image 20241115140115.png]]

Но когда мы работаем в микросервисной архитектуре, в которой у каждого микросервиса своя БД - работа с транзакциями  становится намного сложнее. 

Пусть у нас пришел request в микросервис Orders для создания заказа, он в своей БД создал в таблице заказов заказ. Дальше он обращается к микросервису Products, который должен зарезервировать товар для пользователя, чтобы другие пользователи не могли купить. Поэтому микросервис Products в своей БД также изменяет данные по этому продукту, который заказал пользователь. Потом мы обращаемся к 3-му микросервису для получения информации о платежных данных пользователя. И потом обращаемся к микросервису оплаты и тут происходит ошибка! И что теперь делать ? У нас БД у Orders и Products находятся в неправильном состоянии, нужно все откатить. Но как? Теперь откаты требуют изменения в разных БД! 
![[Pasted image 20241115140702.png]]

Для решения таких проблем придуман паттерн Saga.
### Saga
Сага паттерн нужен для того, чтобы наладить консистентность данных между микросервисами в распределенных транзакциях.
Есть 2 способа для реализации Saga:
- Хореография
- Оркестрация

### Хореография
![[Pasted image 20241115151519.png]]
Клиент хочет сделать заказ и Order Microservice получил запрос на заказ. Он изменил у себя БД и когда закончил, то отправляется event Order Created в message broker. На этот event подписан Products Microservice. Когда этот event приходит, то начинает работать Products Microservice и изменят уже у себя БД и делает, что ему надо и затем publish event Product Reserved, который слушает уже третий микросервис. И т.д. 

Т.е. у нас получается, что event который мы отправляем тригерит начало работы другого микросервиса, который слушает этот эвент и потом этот другой микросервис создает event, который слушает третий и т.д. Т.е. эвенты тригерят работу. И это происходит в определенном порядке друг за другом! И мы можем считать весь этот цикл одной транзакцией, т.е. шаги на картинке от 1 до 8 - это одна транзакция.

И если на каком-то из шагов происходит ошибка, то мы rollback делаем этих всех операций.
Но как сделать rollback?   
Например, в Payment Microservice произошла ошибка. Тогда дальнешие шаги(5-8) уже конечно же не делаются, а Payment Microservice публикует Card Authorization Failed Event - этот event нужен как раз для того, чтобы запустить цепочку обратных операций, чтобы восстановить состояние системы. Этот Failed event слушает Products Microservice, который теперь может отменить свои локальные изменения в БД и после этого запаблишить еще один Failed Event, чтобы теперь Orders Microservice мог узнать что произошла ошибка и откатить изменения. После этого Orders Microsevice может запаблишить Rejected Event если захочет, если вдруг в нашей системе кто-то слушает такие эвенты для ведения статистики отказов или еще чего-либо.
![[Pasted image 20241115152213.png]]

Кратко - если какой-то из шагов в Saga Flow fails микросервисы начинают выполнять компенсирующие транзакции. Компенсирующие транзакции нужны как раз для того, чтобы отменить изменения, которые произошли в нашей системе. И компенсирующие транзакции выполняются в обратном порядке относительно исходных транзакций:
![[Pasted image 20241115152717.png]]
![[Pasted image 20241115152738.png]]
### Оркестрация
Разберемся сначала вариант, когда ошибок нет.

Первое отличие от хореографии - это то, что в одном из микросервисов есть сущность Saga, которая является как бы менеджером, который следит за исполнением бизнес логики другими микросервисами.  В Orders Service пришел HTTP запрос на заказ, он обработал этот запрос(мог добавить в БД сущность заказа) и после этого отправляет event 1. Order Created Event. Этот event слушает как раз Saga и после этого паблишит сообщение 2. Reserve Product Command. Это сообщение слушает Products Service, делает какую-то обработку, изменяет в БД что-нибудь и после того, как закончил отправляет 3. Product Reserverd Event. Этот event снова слушает saga и отправляет после него 4. Process Payment Command, которую уже слушает Payment Service и т.д.
![[Pasted image 20241115154416.png]]

Теперь разберем вариант, что будет, если произойдет ошибка, например, в Payment Service. Payment Service слушал 4. Process Paymend Command начал обрабатывать оплату и произошла ошибка, после этого он отправляет 7. Card Authorization Failed. Этот Event слушает сага и теперь ей нужно отправить компенсирующие эвенты, причем снова в обратном порядке тому, как изначально шли эвенты. Т.е. у нас до 4. Process Payment Command был event 3. Product Reserved Event, значит, мы должны отправить компенсирующую команду для этого эвента - 8. Cancel Product Reserved Command. Это сообщение слушает Products Service, он выполняет отмену действий с БД, которую совершил и после этого отправляет 9. Product Reserv Canceled Event, т.е. сообщает Saga, что он все сделал, чтобы отменить то, что изменил и после этого сага отправляет еще одну команду, чтобы ее послушал Orders Service и уже у себя отменил заказ. 
![[Pasted image 20241115154329.png]]

### С теорией понятно, но как все это реализовать? 
Это довольно сложно сделать с нуля, поэтому есть специальные фреймворки, которые решают эту проблему. Мы будем использовать Axon, который использует CQRS подход и отлично интегрируется со Spring.

### Что же такое CQRS
Command-Query Responsibility Segregation.

В CQRS отвественность компонентов разделяется на 2 части - Commands and Query.

Commands - описывают желание изменения состояния приложения(тригеры для выполнения действия). Например, createProduct или deleteProduct. Такие команды обычно представляют из себя HTTP запросы - POST, PUT, DELETE, PATCH. 
Query - запросы на получение какой-то информации. Это GET запросы.
![[Pasted image 20241115160858.png]]
На картинке выше мы можем заметить, что Commands и Query находятся в одном микросервисе. Если нам нужно масштабироваться, то мы можем разделить Commands и Query на два разных микросервиса! Первый микросервис будет обрабатывать commands, а второй микросервис queries. 
![[Pasted image 20241115162629.png]]
Один микросервис будет иметь End points, который будут принимать POST, PUT ... запросы, а второй - GET. Причем т.к. они теперь независимые, то мы можем в зависимости от нагрузки деплоить их независимо и добавлять инстанты. Например, если у нас много GET запросов, то мы можем увеличивать число инстансов Query микросервиса.

В Command:
- Rest Controller - слушает POST, PUT, DELETE, PATCH
- Commands Handler - исполняет сами команды на изменение
- Есть БД, которая может быть при желании оптимизирована для write операций.
В Query:
- Rest Controller - GET
- Query Handler - извлекает
- БД может быть оптимизирована для READ операций. 
- Events Handler - узнаешь позже

Но если у нас при таком разделении две БД, то как бд из Query узнает информцию, которая была занесена в БД из Command? Здесь нам поможет очередь сообщений.
Когда Command сделал запись, то он делает publish event о том, что он изменил. Т.е. в этом evente содержится информация о том, что изменилось(например, обновили информацию о продукте каком-то и говорим, что теперь по такому продукту такая информация). И другие микросервисы могут слушать этот эвент и как-то реагировать.
![[Pasted image 20241115163429.png]]
Это и делает Query микросервис. Events Handler как раз слушает различные events, которые связаны с тем, что состояние БД могло измениться. И синхронизирует READ БД в соответствие с этими ивентами.
![[Pasted image 20241115163619.png]]
И в таком случае очень круто, что микросервисы даже не знают друг о друге! Т.е. нет никаких портов, куда отправлять event просто очередь. Мы получаем очень независимую структуру!

Подведем итог по типам сообщений в CQRS:
- Command - описываем желание изменить как-то состояние системы. Например, создать продукт.
- Query - описывает желание получение информации. 
- Event - уведомление о том, что состояние системы изменилось.
![[Pasted image 20241115164004.png]]

### Event Sourcing
Для изучения рассмотрим его в сравнении с тем, как происходит работа с БД в наших обычных приложениях.
Клиент делает запрос на созданеие product, мы сохраняем его в БД. Дальше клиент делает запрос на обновление и мы обновляем уже существующую запись в БД. Если он сделает еще один такой запрос на обновление - процесс повторится. Неважно сколько мы сделаем обновлений у нас в БД всегда будет храниться запись в самом последнем состоянии.
![[Pasted image 20241115164354.png]]

Теперь посмотрим, как все происходит в Event Sourcing.
Когда клиент делает запрос на создание нового продукта, мы обрабатываем этот запрос, например, добавляем в БД. Но помимо этого сохраняем event о его желании создать продукт. Например, это будет event = ProductCreatedEvent. Мы сохранили его в некоторую БД, которая называется Event Store. Дальше, если клиент захотел обновить сущность, то мы также сохраняем этот event в Event Store. И при следующем запросе клиента на обновление он также сохраняется в Event Store. Т.е. у нас помимо того, что в БД хранится актуальное состояние продукта(т.е. мы при запросах на изменения изменяем продукт в БД), еще и хранится история изменения продукта, причем реально в том порядке, в котором приходили запросы от клиента!
![[Pasted image 20241115164912.png]]
И это круто, поскольку у нас есть история изменения продукта и мы можем использовать ее для того, чтобы реконструировать состояние продукта до того, которое мы захотим, т.е. теперь знаем, как сделать откат!

### Рассмотрим, как Event Sourcing вклинивается в CQRS приложение
Приходит запрос в Command на создание продукта, Commands Handler создает event ProductCreatedEvent и сохраняет его в Event Store! Т.е. в эту БД мы как раз только пишем, поэтому и можем оптимизировать ее под такие нужды! После этого мы публикуем этот event в очередь, чтобы из этой очереди ег опрочитал Query и обновил информацию в своей БД!
![[Pasted image 20241115171328.png]]
Таким образом, главное главное отличие в БД в Command и в Query - это то, что в Command у нас хранится множество записей, которые связаны с одной сущностью, т.е. как она изменялась(ивенты изменения), а в Query в БД у нас хранится актуальная информация по сущности и сущностью связана всего 1 запись!

Сравним эти две БД:
![[Pasted image 20241115172034.png]]
1. Видим, что у нас для одной сущности в Event Store сразу последотвательность записей(events), в то время как в Read Database всего одна запись с актуальными данными сущности.
2. В Read Database хранится ВСЯ информация по сущности, а в Event Store только часть информация, причем сохранятся только то, что должны было измениться, например, при обновлении цены мы видим, что в eventPayload хранится только id и цена.

Также стоит рассказать о механизме Replay
![[Pasted image 20241115172736.png]]
Когда к нам приходит новый event по Update Product, то мы перед тем, как добавлять такой event реконструируем наш Product, выполняя все events, который хранятся в Event Store для того, чтобы прийти к актуальному состоянию продукта и только потом уже добавляем новый event по изменению. Может показаться, что это ударит по производительности, но на самом деле это происходит довольно быстро, а также в Axon есть механизм Snapshots(т.е. сохраняем какое-то состояние) и потом мы можем производить Replay, начиная с определенного snapshot.

Зачем нужен механизм Replay? Он удобен, когда произошел какой-то баг и мы можем выполнить replay до этого момента и посмотреть на текущее состояние сущености и оценить, в каком она была состоянии и почему случился баг при таком состоянии!

### Axon framework
Axon построен на принципах:
- domain-driven design
- secures
- event-driven
Вот такая схема у Axon:
![[Pasted image 20241115173726.png]]

Пришел запрос (command) мы обрабатываем этот запрос, сохраняем в event store event для этого запроса и паблишим этот event. Этот event слушает Event Handling Components и сохраняет изменения в БД. Т.е. имеем соотвествие с CQRS которое разбирали выше. (черный квадратик описывает как раз Query часть на скрине ниже)
![[Pasted image 20241115174503.png]]
Причем Axon дает выбор для БД для Event Store и Read DB для Query составляющей. Мы можем использовать как тот storage, который дает нам Axon, так и любую другую БД.


Axon также содержит дополнительную инфраструктуру - Axon Server. Он управляет всеми маршрутами ивентов и evet store.
![[Pasted image 20241115175143.png]]
Есть два версии Axon Server - standard и enterprise. Enterpise позволяет запускать кластер из Axon Servers. 

Мы можем зайти в веб версию Axon, в которой есть dashboard, где мы можем получать различную информацию:
![[Pasted image 20241115175501.png]]
![[Pasted image 20241115175516.png]]

Есть также Axon console, с помощью которой можно отслеживать performance наших микросервисов.
![[Pasted image 20241115175827.png]]

Мы даже можем посмотреть на диаграмму сообщений:
![[Pasted image 20241115180105.png]]

### Eureka Discovery Service
Ее также называют Spring Cloud Netflix Eureka - т.к. Eureka сначала придумал Netflix для своих нужд, а потом она стала частью Spring Boot.
Что делает Eureka?
Она помогает микросервисам найти друг друга.

Представим, что у нас есть клиентское приложение. Оно хочет пообщаться с нашим Products микросервисом. Но для общения оно должно знать его адрес(IP + port). Если у нас всего 1 микросервис с определенным портом - то никаких проблем нет, нужно на клиента захардкодить порт и все будет работать. Но что, если мы хотим иметь возможность при необходимости поднимать новые инстансы микросервиса Products, как нам быть? Мы не можем на клиенте заранее знать все порты. Тут и помогает Eureka. Каждый раз при старте микросервис регистрирует себя в Eureka, передавая свой порт на котором он работает. И в Eureka теперь хранятся все адреса микросервисов. Причем, если мы решим, что нам больше не нужно часть инстансов, то Eureka просто удалит их из своего хранилища.
![[Pasted image 20241116170424.png]]

Но не решена проблема, что клиент не знает порты. Тут помогает API Gateway, адрес которого всегда определенный и в него клиент и делает свой запрос, когда хочет отправить запрос в Products микросервис. API Gateway узнает у Eureka адреса всех инстансов этого микросервиса, к которому сделал запрос клиент и с помощью Load Balancer балансирует нагрузку между несколькими инстансами одного и того же микросервиса.
![[Pasted image 20241116170818.png]]

### Реализация Eureka
Eureka - это полноценное приложение. Мы создаем Spring Boot приложение, добавляем зависимость Eureka Server и конфигурируем application.properties файл.

А потом уже в нашем микросервисе добавляем зависимости, указываем адрес, где работает eureka(он настраивается как раз в конфигурационном файле Eureka приложения). И навешиваем аннотацию @EnableDiscoveryClient
И дальше у Eureka есть UI, где мы можем смотреть зарегистрированные сервисы.
![[Pasted image 20241116193920.png]]


### Spring Cloud API Gateway
Когда клиент делает запрос, то ему нужно знать точку входа - этой точкой и является Spring Cloud API Gateway, внутри которого есть встроенный Load Balancer. IP адреса для отправки клиентских запросов на конкретные микросервисы Gateway получает из Eureka. Помимо этого у него есть доп функционал. Мы можем писать фильтры и добавлять новый функционал(похоже на фильтры из сервлетов), т.к. все запросы приходят на Gateway и выходят также из него! 
![[Pasted image 20241116202914.png]]


### Мы можем включить автоматический routing в нашем приложении ApiGateway
Для этого нужно использовать в настройках 
spring.cloud.gateway.discovery.locator.enabled=true
### Чтобы приложение каждый раз стартовало с рандомным портом, нужно в application.yml указать port : 0. Тогда мы сможем запускать несколько инстансов одного сервиса и у них будут разные порты, что важно, т.к. мы не можем запустить один и тот же сервис с одним и тем же портом 
![[Pasted image 20241118151128.png]]
Но чтобы в Eureka могли регаться сразу несколько микросервисов одного и того же приложения, то нужно добавить доп настройку в микросервис:
![[Pasted image 20241118151942.png]]
В dashboard у нас будет благодаря этому будет 2 микросервиса! Если мы так не сделаем, то при запуске еще одного инстанса одного и того же микросервиса из-за того, что id по умолчанию равно имени приложения, то просто перетрется информация по прошлому инстансу
![[Pasted image 20241118152432.png]]

### Load Balancing
По дефолту Spring Cloud Api Gateway использует встроенный Load Balancer - Ribbon.


### Axon Server
Axon Server можно всячески конфигурировать. Для этого нужно просто создать .properteis файлик в директории configuration. И запустить axon server java -jar aonserver.jar - но это если мы скачали jar-ник с axon сайта. 
https://docs.axoniq.io/axon-server-reference/v2024.1/axon-server/administration/admin-configuration/configuration/
![[Pasted image 20241118160346.png]]
Наиболее простые настройки, чисто для примера:
![[Pasted image 20241118160359.png]]
devmode - нужен для того, чтобы появилась кнопка в dashboard axona, чтобы можно было вручную чистить Event Store.

Запуск в докере
docker run --name axonserver -p 8024:8024 -p 8124:8124 -v "/home/user/IdeaProjects/docker-data/data":/axonserver/data -v "/home/user/IdeaProjects/docker-data/eventdata":/axonserver/eventdata -v "/home/user/IdeaProjects/docker-data/config":/axonserver/config axoniq/axonserver
![[Pasted image 20241118161615.png]]
И потом в диреткории config мы создаем файлик axonserver.properties и там прописываем настройки.

Конвенция для имени команд.
![[Pasted image 20241119090748.png]]
Например: Create(verb) + Product(noun) + Command = CreateProductCommand

Command - это просто POJO, в котором мы храним всю необходимую информацию для выполнения команды + id, который нужен для Axon, чтобы решать к какому объекту относится команда. Например, для создания продукта мы в command храним:
![[Pasted image 20241119091520.png]]

В команде по созданию продукта как раз храним такие же поля, т.к. они нужны для создания объекта Product:
![[Pasted image 20241119091107.png]]

В контроллере мы создаем объект команды и затем отправляем эту команду в Command Gateway, которая отправляет команду в  Command Bus по которой отправляются команды в обработчик команд!

Можно думать об Command Gateway - как об API, который позволяет отправлять команды.
А Command Bus приинмает эти команды и направляет уже в обработчики команд, которые мы напишем! Т.е. это диспетчек команд, как диспатчер сервлет, который принимает все запросы и направляет их в соответствующие контроллеры. Если для Command Bus не будет Command Handlera, который обрабатывает данную команду, то будет выброшено исключение.
Вот такая схемка:
![[Pasted image 20241119092243.png]]

Вот так выглядит контроллер пока что. Создали команду и отправили ее через commandGateway, который получили из DI.
![[Pasted image 20241119094022.png]]


У commandGateway есть два основных метода:
- send - отправили команду и нам возвращается CompletableFuture, который мы сможем использовать потом, когда команда выполнится.
- sendAndWait - отправили команду и ждем результата. Т.е. это блокирующий вызов.
![[Pasted image 20241119092636.png]]

### Aggregate класс
Aggregate класс - это сердце нашего приложения. Разберем его на примере Product. Он хранит внутри себя:
- Текущее состояние Product, т.е. как раз те поля title, price, quantity, которые мы определили для нашего продукта.
- Command Handlers - это те команды, которые будут поступать из Command Bus в наш Aggregate Object.
- Business Logic - при обработки команды может быть выполнена различная бизнес логика. Это может быть валидация, т.е. может быть попытка создать некорректный Product объект и тут же и будет вынесено решение о том, чтобы не создавать невалидный объект.
- Event Sourcing Handlers Methods - они обрабатывают events, который приходят из Event Store для восстановления объекта. Axon сначала создает полностью пустой Aggregate object, в котором пустое состояние. И дальше он использует Event Store из которого забирает events, связанные с aggregate object и выполняет events для того, чтобы реконструировать объект. Т.е. если пришла команда UpdateProductCommand, то для ее выполнения нужно сначала восстановить состояние Product перед тем как вызвать обновление.
![[Pasted image 20241119093209.png]]

![[Pasted image 20241119135628.png]]

Создадим aggregate класс для Product и в конструкторе обработаем в нем CreateProductCommand:
![[Pasted image 20241119100301.png]]
После валидации, если все прошло хорошо, то мы должны сделать publish event, чтобы о создании event все узнали! 
Именование для events:
![[Pasted image 20241119100234.png]]
В случае создания Product: ProductCreatedEvent

Создаем объект eventa, в нем мы сами решаем, что хотим хранить. В случае создание нам нужно сохранить все данные для того, чтобы в Query части нашего CQRS приложение можно было сохранить этот Product в БД, а для этого нужна вся информация!
![[Pasted image 20241119100718.png]]

Теперь мы должны запаблишить этот event. Сделаем это после валидации в конструкторе, который обрабатывает CreateProductCommand. Для этого создаем сам объект event, а потом используем AggregateLifecycle.apply метод, который публикует этот event. Но важно, что сначала этот event доходит до EventHandlers ВНУТРИ НАШЕГО ProductAggregate, чтобы мы могли узнать об этом изменении для изменения ProductAggregate объекта, а только потом он уходит наружу для других EventHandlers других классов!
![[Pasted image 20241119101241.png]]

Теперь напишем в ProductAggregate EventHandler, который обработает productCreatedEvent, который мы отправили вызовом AggregateLifecycle.apply

По Axon конвенции мы называем методы on и вешаем аннотацию @EventSourcingHandler в котором принимаем event, который обрабатываем. Внутри обработчиков мы должны быть нацелены только на обновление внутреннего состояние AggregateObject, а не выполнять какую-то бизнес логику! Для бизнес логики используем обработчик команд. Вот так выглядит метод, который будет обрабатывать productCreatedEvent внутри ProductAggregate:
![[Pasted image 20241119102153.png]]
Также мы внутри ProductAggregate храним состояние для Product, которое и будем обновлять внутри EventHandlers. И стоит заметить, что мы должны использовать productId и аннотацию @AggregateIdentifier! С помощью этого поля Axon как раз и понимает, как связать команду, которая к нему пришла с Aggregate объектом, внутри которого есть обработчики команд, которые будут обрабатывать эту команду.
![[Pasted image 20241119102135.png]]

Таким образом, что имем?
POST запрос приходит в контроллер, там мы создаем CommandCreateProduct и отправляем через CommandGateway эту команду. У команды должно быть поле:
```java
@TargetAggregateIdentifier 
private final String productId;
```
Чтобы Axon мог связать команду и AggregateObject.
Эта команда приходит в AggregateObject, в котором есть метод(или конструктор, как было в случае CreateProductCommand), помеченный аннотацией @CommandHandler и который в качестве параметра принимает эту команду. В нем мы выполняем всю бизнес логику, которую хотим - валидируем, например. 

И после этого, если все хорошо, то мы паблишим event через AggregateLifecycle.apply(), который сначала выполняется для методов, которые слушают Event внутри AggregateObject класса(такие методы помечены аннотацией @EventSourcingHandler), а потом уже публикуется для других слушателей event-а.

Далее выполняется код в @EventSourcingHandler, внутри которого мы обновляем внутреннее состояние AggregateObject. Также обязательное поле:
```java
@AggregateIdentifier  
private String productId;
```

### Теперь поработем с Query частью нашего CQRS
Мы научились немного работать с Command частью, теперь же нам нужно написать Query часть, которая будет сохранять product в БД. Помечаем аннотацией Component и создаем метод, который помечен @EventHandler для обработки ProductCreatedEvent и сохраняем его через обычный Jpa репозиторий.
![[Pasted image 20241119132738.png]]

Важно, что при старте нашего приложения @HandlerEvents автоматически начинает обрабатывать ивенты, которые не были обработаны ранее.

Для подключения к веб-интерфейсу h2 консоли используется /h2-console путь, но перед ним, если мы используем spring cloud api gateway, то нужно также указывать необходимый url.

Теперь реализуем схему с получением данных.
![[Pasted image 20241119132947.png]]

![[Pasted image 20241119135757.png]]
Стоит заметить, что у Query нет прослойки в виде Even Bus, как у Command API. 

В случае Query у нас приходит запрос на контроллер, в контроллере мы создаем Query объект(аналогия с Command объектом) и в этот Query объект мы уже помещаем информцию, которая необходима для query запроса(например, если реализуем пагинацию, то какую страницу отобразить и количество страниц). 

Созданный Query объект. Причем есть конвенция, которая также представлена на скрине:
![[Pasted image 20241119140230.png]]

QueryController, который как раз создает объект FindProductsQuery и передает его через gateway. В метод query вторым параметром передается то, что должен вернуться обработчик query. Т.к. нам нужен список, то мы используем ResponseTypes.multipleInstances. А возвращается нам future, поэтому join.
![[Pasted image 20241119140321.png]]


И дальше этот Query отправляем через QueryGateway на обработку в метод, помеченный аннотацией @QueryHandler(аналогия с @CommandHandler, который есть внутри AggregateObject). Внутри него мы общаемся с репозиторием и возвращаем то, что хотели вернуть из Query.

А вот и сам класс, внутри которого есть @QueryHandler метод
![[Pasted image 20241119140539.png]]


### Валидация информации перед сохранением в БД

#### Bean Validation
Сначала проверим переданные поля, т.е. произведем раннюю валидацию.
Используем Hibernate Validation(помечаем аннотациями поля)
![[Pasted image 20241119141553.png]]
Документация:
https://hibernate.org/validator/documentation/

Вот такой прикольный вывод ошибок мы получим, если включим две настройки в application.yml:
server:  
  error:  
    include-message: always  - добавляеn message в response(на скрине увидишь)
    include-binding-errors: always - добавляем errors(на скрине также увидишь)
![[Pasted image 20241119144502.png]]

#### Command Validation
Также валидация может потребоваться для команды, которую мы получили в @CommandHandler. Важно, что валидация должна происходить до того, как отправится Event. Зачем такая валидация? Она чаще всего используется для того, чтобы проверить, можно ли выполнить такую команду, основываясь на текущем состоянии AggregateObject. Например, пришла команда ReserveProductCommand - которая говорит, чтобы мы зарезервировали Product. Мы смотрим на текущее состояние нашего AggregateObject и если count у него меньше, чем хотят зарезервировать, то выбрасываем исключение!

Пример валидации, но конкретна этот вариант бесполезный, поскольку мы проверяем это на этапе Bean Validation(Hibernate Validator).
![[Pasted image 20241119144830.png]]


#### Message Dispatch Interceptor
Это еще один способ провалидировать команду. Но теперь уже не в @CommandHandler, а на этапе перед попаданием команды в Command Bus, а, значит, перед попаданием в метод @CommandHandler. Т.е. этот interceptor будет вызываться, когда мы будем отправлять команду через CommandGateway.
![[Pasted image 20241119145448.png]]
Что мы можем сделать в этом interceptore?
- Провалидировать команду
- Добавить в message какую-нибудь метаинформацию или прологировать команду!
- Заблокировать команду, выбросив исключение

Как реализовать Interceptor?
Создаем класс и реализуем MessageDispatchInterceptor
```java
@Component  
@Slf4j  
public class CreateProductCommandInterceptor implements MessageDispatchInterceptor<CommandMessage<?>> {  
  
    //Должен вернуть BiFunction, которая будет обрабатывать команду  
    //Integer - command index    // CommandMessage - result of the function    @Nonnull  
    @Override    public BiFunction<Integer, CommandMessage<?>, CommandMessage<?>> handle(  
            @Nonnull List<? extends CommandMessage<?>> messages  
    ) {  
        return (index, command) -> {  
  
            //прологируем вызванную команду  
            log.info("Intercepted Command: " + command.getPayload());  
  
  
            //Т.к. данный interceptor будет срабатывать для всех команд, которые мы отправляем, то должны проверить  
            //что это нужная команда.            if(CreateProductCommand.class.equals(command.getPayloadType())) {  
                if(command.getPayload() instanceof CreateProductCommand createProductCommand) {  
  
                    //Такую валидацию делаем чисто для примера, понятно, что это все можно проверить на этапе BeanValidation  
                    if(createProductCommand.getPrice().compareTo(BigDecimal.ZERO) <= 0) {  
                        throw new IllegalArgumentException("Price must be greater than zero");  
                    }  
  
                    if(createProductCommand.getTitle() == null || createProductCommand.getTitle().isEmpty()) {  
                        throw new IllegalArgumentException("Title can't be null or empty");  
                    }  
                }  
            }  
  
            return command;  
        };  
    }  
}
```
Но, чтобы он заработал мы должны зарегистрировать его(Создаем такой метод в любом @Configuration классе. Например, в main классе, где запускаем Spring приложение):
```java
// Мы должны зарегистрировать interceptor в CommandBus, чтобы он заработал  
@Autowired  
public void registerCreateProductCommandInterceptor(ApplicationContext context,  
                                                    CommandBus commandBus) {  
    commandBus.registerDispatchInterceptor(  
            context.getBean(CreateProductCommandInterceptor.class)  
    );  
  
}
```

#### Как проверить перед сохранением объекта, что такой объект еще не существует?
Проблема в том, что мы разделили Command и Query. Сохраняем объект мы в Command части, но нам нужно в ней же сделать запрос, которым проверить нет ли такого объекта в БД? Но как мы должны это сделать, вызовом Query? Или самим сходить в Repository? Или какой-то другой вариант? 

Эта проблема описана в одной из статьей на Axon сайте.
![[Pasted image 20241119161549.png]]

Для решения этой проблемы мы заведем в Command части приложения еще одну БДшку - Lookup DB. Она будет хранить только productId и title! А все другие поля она не будет хранить, т.к. единственная цель этой БД - дать нам возможность в Command проверить при создании или обновлении Product, что такой Product существует. Но где мы будем это проверять ? Мы будет это проверять как раз в Interceptore, который написали ранее, который выполняется до того, как Command попадет в CommandHandler. 

Еще важно то, что наша Lookup табличка должна быть синхроинизированна с другой основной БД, т.е. чтобы данные в них по id и title совпадали(title у нас хранится в lookup, поскольку мы указали, что он unique, поэтому также нужно проверять.). Чтобы не было такого, что в lookup страничке нет какой-то инфы, либо наоборот. 

Т.е. мы дожны сохранять изменения как в lookup табличку, так и в основную БД. С основной БД понятно, когда все с командной хорошо, то паблишим event с изменением и потом в EventHandler обновляем БД. Но как поступить с lookup? А для нее мы также будем генерировать event для сохранения и в EventHandlere обрабатывать, но уже этот EventHandler будет в Command.
![[Pasted image 20241119162017.png]]

Создаем Entity, которую будем хранить в Lookup table:
```java
@Data  
@Entity  
@Table(name = "productlookup")  
public class ProductLookupEntity implements Serializable {  
  
    private static final long serialVersionUID = -1040059442356059255L;  
  
    @Id  
    @Column(unique = true)  
    private String productId;  
    @Column(unique = true)  
    private String title;  
}
```
И репозиторий:
![[Pasted image 20241119164403.png]]

@ProcessingGroup("product-group") - для логического объединения всех EventHandlers, которые обрабатывают events, связанные с Product.
Axon для каждой такой группы создает отдельный tracking event processor. Этот tracking event processor будет использовать специальный tracking token, который будет использовать для избежания множественной обработки одного и того же эвента в разных тредах и нодах. Также этот механизм используется для Rollback операций. (Стоит почитать отдельно, зачем это нужно). 

Как я понял - это еще нужно для того, чтобы в том потоке, в котором инициировался этот event выполнилась и его обработка, чтобы не было такого, что мы в нашем потоке создали эвент, а он обработался и другим потоком и нашим. Но лучше реально почитать об этом...

Но похоже поведение зависит еще и от типа Tracking Event Processor. 

ProductLookupEventsHandler - event handler на событие CreateProductEvent. Он должен добавить в lookup БД новую сущность. Почему он не проверяет? Потому что мы делаем проверку на то, существует сущность или нет в interceptore, который вызывается раньше, чем EventHandler. 
```java
@Component  
@ProcessingGroup("product-group") // чтобы логически объединить все handler-ы, которые обрабатывают Product эвенты в одну группу  
@RequiredArgsConstructor  
@Slf4j  
public class ProductLookupEventsHandler {  
  
    private final ProductLookupRepository productLookupRepository;  
  
    @EventHandler  
    public void on(ProductCreatedEvent productCreatedEvent) {  
        log.error("ProductLookupEventsHandler");  
  
        ProductLookupEntity productLookupEntity = new ProductLookupEntity(  
                productCreatedEvent.getProductId(), productCreatedEvent.getTitle()  
        );  
        productLookupRepository.save(productLookupEntity);  
    }  
}
```

Код interceptora, который проверяет нет ли такой сущности уже в БД. Если есть, то выбрасывает исключение, а значит event-ы, которые инициируются уже после interceptora не будут вызваны.
```java
@Component  
@Slf4j  
@RequiredArgsConstructor  
public class CreateProductCommandInterceptor implements MessageDispatchInterceptor<CommandMessage<?>> {  
  
    private final ProductLookupRepository productLookupRepository;  
  
    //Должен вернуть BiFunction, которая будет обрабатывать команду  
    //Integer - command index    // CommandMessage - result of the function    @Nonnull  
    @Override    public BiFunction<Integer, CommandMessage<?>, CommandMessage<?>> handle(  
            @Nonnull List<? extends CommandMessage<?>> messages  
    ) {  
        return (index, command) -> {  
  
            //прологируем вызванную команду  
            log.info("Intercepted Command: " + command.getPayload());  
              
            //Т.к. данный interceptor будет срабатывать для всех команд, которые мы отправляем, то должны проверить  
            //что это нужная команда.            if (CreateProductCommand.class.equals(command.getPayloadType())) {  
                if (command.getPayload() instanceof CreateProductCommand createProductCommand) {  
                    ProductLookupEntity entity = productLookupRepository.findByProductIdOrTitle(  
                            createProductCommand.getProductId(),  
                            createProductCommand.getTitle()  
                    );  
                    if (entity != null) {  
                        throw new IllegalStateException(  
                                String.format("Product with productId %s or title %s already exists.",  
                                        createProductCommand.getProductId(), createProductCommand.getTitle())  
                        );  
                    }  
                }  
            }  
  
            return command;  
        };  
    }  
}
```

ProductEventsHandler - для сохранения Product в основную БД приложения.
```java
//также часто называют ProductProjection  
@Component  
@RequiredArgsConstructor  
@ProcessingGroup("product-group")  
@Slf4j  
public class ProductEventsHandler {  
  
    private final ProductsRepository productsRepository;  
  
    @EventHandler  
    public void on(ProductCreatedEvent event) {  
  
        log.error("ProductEventsHandler");  
        ProductEntity product = new ProductEntity();  
        BeanUtils.copyProperties(event, product);  
  
        productsRepository.save(product);  
    }  
}
```

Логика, которую имеем.
Приходит POST запрос от клиента о создании объекта. Мы создаем command CreateProductCommand и с помощью CommandGateway отпраляем ее на обработку. У нас есть interceptor, который вызывается для каждой команды и для CreateProductCommand проверяет, нет ли в Lookup БД уже такой сущности. Если она есть, значит, ошибка, т.к. создавать дубликаты запрещено. Говорим пользователю об ошибке и заканчиваем работу. После прохождения interceptora команда идет в AggregateObject, конструктор которого помечен аннотацией CommandHandler и он хендлит эту команду. После чего вызывает event через AggregateLifecycle, который сначала попадает в @EventSourcingHandler, в котором обновляются поля для AggregateObject. После чего этот эвент попадает в ProductLookupEventsHandler для сохранения нового Product в Lookup БД, а потом в ProductEventsHandler и сохраняется уже в полноценную БД для Query.

### Error Handling
Научимся наконец-то отменять изменения в БД. Т.е. если вдруг в Evente(а это уже последний этап, где мы реально уже изменяем в БД данные) произошла ошибка.
Для начала научимся отменять изменения внутри одного микросервиса, а потом уже и для распределенных транзакций с сага.

В try catch, который мы можем повесить в controller или используя @ControllerAdvice мы можем отлавливать ошибки, которые произошли в контроллере, в interceptore или в CommandHandlere. Но мы не можем обработать ошибку, которая произошла в EventHandler. Причем стратегия ошибок в Event Handlers такая, что если выбросилось исключение, то сообщение об ошибке запоминается, но выполнение ПРОДОЛЖАЕТСЯ В ДРУГИХ Event Handlers. Т.е. в моем handlere произошла ошибка и я дальше выполниться не смог, а вот другие без проблем смогут обрабатывать этот event, хотя это неправильно! Мы должны остановить обработку ошибочного эвента.

Причем commandHandler, который вызвал publish эвента уже никак не реагирует, для него все закончилось хорошо и в Controller не вернется никакой ошибки и мы отправим пользователю успешный ответ, хотя на самом деле в Event Handlere произошла ошибка!

Нам никто не мешает исползовать try catch внутри Event Handler методов, но проблема в том, что об этой ошибке никак не узнает controller. А мы бы хотели, чтобы она дошла до контроллера и была обработана! Для этого нужно будет использовать ListenerInvocationErrorHandler

Благодаря нему, когда ошибка произойдет, то мы остановим выполнение того Event Handlera, в котором произошла ошибка, а также остановим выполнение других Event Handlers, которые также обрабатывали этот event!!! А также сможем вернуть ошибку RestController классу и он вернет пользователю сообщение об ошибке! А также вся транзакция сделает rollback и откатятся все изменения! 

И чтобы все это работало нам и нужно, чтобы Event Handlers, которые обрабатывают одни и те же events находились в одной группе, которую обрабатывает Subscribing Event Processor.
![[Pasted image 20241119181432.png]]

### Что такое event processor?
Event Processor - это компонент, который направлен на выполнение технических аспектов, связанных с предоставлением эвентов до наших event handlers!
Есть два вида event processors:
![[Pasted image 20241119182202.png]]
#### Tracking
Это такой event processor, который работает в отдельном потоке от потока, который создает эвенты. Он забирает сообщения из источники эвентов.

Если произойдет ошибка, то он перейдет в Error мод Он отпустит token и затем будет пытаться выполнить этот эвент еще раз с увеличивающимся периодом, начиная с 1 секунды до 60 секунд. Т.е. он попробует перевыполнить event, если не получилось, то он удваивает время через которое попробует еще раз, т.е. уже через 2 секунды и снова попробует выполнить, если не получилось, то через 4 секунды и т.д. до того, пока не превысит 60 секунд.
Зачем такие периоды ожидания? Они нужны для того, чтобы если вдруг другая node сможет обработать event, то она смогла запросить token у нашего Tracking Processor-a и завершить обработку eventa.
#### Subscribing
Это такой event processor, который работает в том же потоке, который создает эвенты! Т.е. грубо говоря, в Aggregate мы вызвали event и этот же поток, который создает event отвечает и за доставку этого эвента в @EventHandler.

Если прозойдет ошибка, то сообщит о ней в компонент, который предоставил этот event(до паблишера этого эвента). Т.е. Subscribing позволит паблишеру обработать ошибку. Если мы распространим(propagate) ошибку до конца, то сможем откатить ее!

В курсе мы будем для отката ошибки использовать Subscribing вариант.

