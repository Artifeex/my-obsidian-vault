### Что такое микросервисы?
![[Pasted image 20241115115220.png]]![[Pasted image 20241115115346.png]]
Spring Cloud - это environment, который предоставляет множество услуг для микросервисов, написанных на SpringBoot.
### Microservice vs Monolit
![[Pasted image 20241115115521.png]]
Монолит - это одно большое приложение, которое содержит в себе контроллеры, каждый из которых отвечает за какую-то функциональность. И если мы захотим изменить в каком-то контроллере код, то придется ребилдить все приложение, а это для очень больших монолитов может занимать приличное время.
В микросервисах же у нас есть маленькие веб-сервисы(просто приложенька отдельная), которые отвечают за свой функционал, как раньше это делали контроллеры. И плюсом является то, что они меньше, поэтому в них проще разобраться, каждый микросервис может быть написан на различных технологиях, в то время как монолит обязан быть написан на одном языке. 

Но сложностью в случае микросервисов является общение между компонентами. В монолите мы просто заимпортили один сервис в другой сервис и у нас все хорошо. 
Микросервисы чаще всего общаются по HTTP.
![[Pasted image 20241115120054.png]]
На диаграмме выше мы видим, что у нас есть клиенты, которые шлют HTTP запросы для работы с нашими сервисами. Красный квадрат - это как раз SpringCloud. В нем есть микросервис API Gateway - просто снова приложенька на Spring Boot. И другие составляющие - такж являеются просто приложениями. А также у нас есть множество микросервисов, которые уже общаются между собой по HTTP.
![[Pasted image 20241115120443.png]]
Еще важной составляющей для микросервисов является то, что мы можно отдельно их редеплоить и они могут жить независимо от других микросервисов.

Представим, что у нас есть монолит:
![[Pasted image 20241115120639.png]]
И он рос, рос и мы решили распилить его на микросервисы.
Когда мы создаем микросервисы, то у нас теперь для каждого микросервиса своя БД. Этот паттерн называется database per class. И другие микросервисы не могут лазить в БД нашего микросервиса.
![[Pasted image 20241115120806.png]]
Если нагрузка на какой-то микросервис растет, то мы можем запустить на одном hoste, на котоом работает микросервис сразу несколько инстансов этого микросервиса - такой паттерн называется multiple instances per host. И мы можем запускать сколько угодно микросервисов Products на одном сервере, поскольку у каждого из них свой port и поэтому они не конфликтуют.
![[Pasted image 20241115121015.png]]

Но у нас появляется проблема. Когда был монолит, то из-за того, что он был запущен в одном instance, то мы на клиенте знали его port и тогда понятно, куда отправлять наши HTTP запросы. Но теперь у нас несколько микросервисов, каждый занимается какими-то своими делами, так еще и есть возможность запуска сразу несколько одинаковых микросервисов(products), причем при таком запуске порты генерируется динамически, т.е. порт микросервиса мы можем узнать только при старте нашего микросервиса. 

Сначала решим проблему с тем, что клиент не знает порт. Эту проблему решает API Gateway - приложение, которое работает на известном порту и к нему и делает запрос клиент. Это приложение знает о наших микросервисах и их портах и будет перенаправлять запросы на соотвествующий микросервис. Но откуда оно их знает? Ведь мы сказали, что порты динамические и известны только при старте приложения. Для этого существует Eureka Service Discovery - еще одна программка, которую можно считать адресной книжкой, в которой хранится информация о микросервисах. Когда микросервис запускается, то он регистрируется в Eureka Service, чтобы сообщить как раз свой порт. И тогда API Gateway может спросить у Eureka порт нужного микросервиса для отправки. 

Разберемся теперь с вопросом о нескольких инстансах одного микросервиса. Мы их создали из-за повышенной нагрузки и теперь нам нужно распределить запросы по ним. Поэтому появляется Load Balancer, который и будет заниматься распределением нагрузки. Он может быть как встроен в API Gateway, так и быть отдельным объектом, с который API Gateway будет работать.
![[Pasted image 20241115121545.png]]

Решим еще одну проблему. У каждого микросервиса есть свой конфигурационный файлик, в котором могут находиться различные настройки. Поэтому нам бы хотелось иметь какой-то централизованное место, где мы могли бы настраивать эти конфигурации. Этим центральным местом будет Config Server, который позволит нам изменять какие-то конфигурации на лету, т.е. не придется отстанавливать микросервис для каких-то изменений
![[Pasted image 20241115133251.png]]

Мы рассмотрели 4 составляющие микросервисной архитектуры:
![[Pasted image 20241115133531.png]]
Но есть и множество других.

### Event-Driven microservice
Микросервисы могут общаться по обычному HTTP. Делаю request и получая Response. Этот подход подходит под множество usecases, но не всегда.
![[Pasted image 20241115133846.png]]

Но представим ситуацию, что есть микросервис А и он хочет доставить одно и то же сообщение сразу множеству микросервисов. В таком случае нам уже не поможет то общение, которое мы описали выше. Т.е. да, мы бы могли с каждым микросервисом так обменяться, но это долго, поскольку если микросервисов 10-ки, то это 10-ки отправок одних и тех же сообщений и ожидания ответов, а также могут добавляться новые микросервисы, которые также будут хотеть получать сообщения.

Поэтому решением является Event-Driven подход, в котором микросервис А отправляет сообщения в брокер сообщений, а другие читают из этого брокера. Такая модель еще называется Producer/Consumer или Publisher/Subscriber. 
![[Pasted image 20241115134314.png]]

Producer может отправлять различные типы сообщений или events, а consumer получает эти events. И как раз потому что producer publish event или message такая архитектура общения и называется event driver или message driven.

Также стоит заметить, что Event-Driven architecture является асинхронной! Т.е. Когда в микросервис А приходит какая-то команда, которую ему нужно выполнить, то он publish event в message broker и не дожидается того, когда этот event и главное КЕМ этот event будет обработан. Он свое дело сделал, принял команду и создал event, который уже другие должны обработать. И микросервис А не ожидает какого-то респонса от subsriber-ов. Он сразу после того, как запушил event отправляет response для того запроса, который к нему пришел. 
![[Pasted image 20241115135207.png]]

Причем еще стоит заметить, что если какой-то из consumers отвалится, то ничего не поломается, т.к. брокер, в который отправили event продолжит хранить сообщение у себя. И потом, когда consumer микросервис очнется, то он сможет без проблем прочитать сообщения из брокера.

В случае же не event driven подхода
![[Pasted image 20241115135713.png]]
Если микросервис B помрет, то микросервис А ничего сделать не может, ему нужно дождаться ответа.

### Transactions in microservice
В случае монолита с транзакциями работать довольно просто. Мы запустили транзакцию, выполняем внутри нее какие-то шаги и потом заканчиваем транзакцию. И если в течение транзакции произошла какая-то ошибка, то мы без проблем делаем rollback всех действий.
![[Pasted image 20241115140115.png]]

Но когда мы работаем в микросервисной архитектуре, в которой у каждого микросервиса своя БД - работа с транзакциями  становится намного сложнее. 

Пусть у нас пришел request в микросервис Orders для создания заказа, он в своей БД создал в таблице заказов заказ. Дальше он обращается к микросервису Products, который должен зарезервировать товар для пользователя, чтобы другие пользователи не могли купить. Поэтому микросервис Products в своей БД также изменяет данные по этому продукту, который заказал пользователь. Потом мы обращаемся к 3-му микросервису для получения информации о платежных данных пользователя. И потом обращаемся к микросервису оплаты и тут происходит ошибка! И что теперь делать ? У нас БД у Orders и Products находятся в неправильном состоянии, нужно все откатить. Но как? Теперь откаты требуют изменения в разных БД! 
![[Pasted image 20241115140702.png]]

Для решения таких проблем придуман паттерн Saga.
### Saga
Сага паттерн нужен для того, чтобы наладить консистентность данных между микросервисами в распределенных транзакциях.
Есть 2 способа для реализации Saga:
- Хореография
- Оркестрация

### Хореография
![[Pasted image 20241115151519.png]]
Клиент хочет сделать заказ и Order Microservice получил запрос на заказ. Он изменил у себя БД и когда закончил, то отправляется event Order Created в message broker. На этот event подписан Products Microservice. Когда этот event приходит, то начинает работать Products Microservice и изменят уже у себя БД и делает, что ему надо и затем publish event Product Reserved, который слушает уже третий микросервис. И т.д. 

Т.е. у нас получается, что event который мы отправляем тригерит начало работы другого микросервиса, который слушает этот эвент и потом этот другой микросервис создает event, который слушает третий и т.д. Т.е. эвенты тригерят работу. И это происходит в определенном порядке друг за другом! И мы можем считать весь этот цикл одной транзакцией, т.е. шаги на картинке от 1 до 8 - это одна транзакция.

И если на каком-то из шагов происходит ошибка, то мы rollback делаем этих всех операций.
Но как сделать rollback?   
Например, в Payment Microservice произошла ошибка. Тогда дальнешие шаги(5-8) уже конечно же не делаются, а Payment Microservice публикует Card Authorization Failed Event - этот event нужен как раз для того, чтобы запустить цепочку обратных операций, чтобы восстановить состояние системы. Этот Failed event слушает Products Microservice, который теперь может отменить свои локальные изменения в БД и после этого запаблишить еще один Failed Event, чтобы теперь Orders Microservice мог узнать что произошла ошибка и откатить изменения. После этого Orders Microsevice может запаблишить Rejected Event если захочет, если вдруг в нашей системе кто-то слушает такие эвенты для ведения статистики отказов или еще чего-либо.
![[Pasted image 20241115152213.png]]

Кратко - если какой-то из шагов в Saga Flow fails микросервисы начинают выполнять компенсирующие транзакции. Компенсирующие транзакции нужны как раз для того, чтобы отменить изменения, которые произошли в нашей системе. И компенсирующие транзакции выполняются в обратном порядке относительно исходных транзакций:
![[Pasted image 20241115152717.png]]
![[Pasted image 20241115152738.png]]
### Оркестрация
Разберемся сначала вариант, когда ошибок нет.

Первое отличие от хореографии - это то, что в одном из микросервисов есть сущность Saga, которая является как бы менеджером, который следит за исполнением бизнес логики другими микросервисами.  В Orders Service пришел HTTP запрос на заказ, он обработал этот запрос(мог добавить в БД сущность заказа) и после этого отправляет event 1. Order Created Event. Этот event слушает как раз Saga и после этого паблишит сообщение 2. Reserve Product Command. Это сообщение слушает Products Service, делает какую-то обработку, изменяет в БД что-нибудь и после того, как закончил отправляет 3. Product Reserverd Event. Этот event снова слушает saga и отправляет после него 4. Process Payment Command, которую уже слушает Payment Service и т.д.
![[Pasted image 20241115154416.png]]

Теперь разберем вариант, что будет, если произойдет ошибка, например, в Payment Service. Payment Service слушал 4. Process Paymend Command начал обрабатывать оплату и произошла ошибка, после этого он отправляет 7. Card Authorization Failed. Этот Event слушает сага и теперь ей нужно отправить компенсирующие эвенты, причем снова в обратном порядке тому, как изначально шли эвенты. Т.е. у нас до 4. Process Payment Command был event 3. Product Reserved Event, значит, мы должны отправить компенсирующую команду для этого эвента - 8. Cancel Product Reserved Command. Это сообщение слушает Products Service, он выполняет отмену действий с БД, которую совершил и после этого отправляет 9. Product Reserv Canceled Event, т.е. сообщает Saga, что он все сделал, чтобы отменить то, что изменил и после этого сага отправляет еще одну команду, чтобы ее послушал Orders Service и уже у себя отменил заказ. 
![[Pasted image 20241115154329.png]]

### С теорией понятно, но как все это реализовать? 
Это довольно сложно сделать с нуля, поэтому есть специальные фреймворки, которые решают эту проблему. Мы будем использовать Axon, который использует CQRS подход и отлично интегрируется со Spring.

### Что же такое CQRS
Command-Query Responsibility Segregation.

В CQRS отвественность компонентов разделяется на 2 части - Commands and Query.

Commands - описывают желание изменения состояния приложения(тригеры для выполнения действия). Например, createProduct или deleteProduct. Такие команды обычно представляют из себя HTTP запросы - POST, PUT, DELETE, PATCH. 
Query - запросы на получение какой-то информации. Это GET запросы.
![[Pasted image 20241115160858.png]]
На картинке выше мы можем заметить, что Commands и Query находятся в одном микросервисе. Если нам нужно масштабироваться, то мы можем разделить Commands и Query на два разных микросервиса! Первый микросервис будет обрабатывать commands, а второй микросервис queries. 
![[Pasted image 20241115162629.png]]
Один микросервис будет иметь End points, который будут принимать POST, PUT ... запросы, а второй - GET. Причем т.к. они теперь независимые, то мы можем в зависимости от нагрузки деплоить их независимо и добавлять инстанты. Например, если у нас много GET запросов, то мы можем увеличивать число инстансов Query микросервиса.

В Command:
- Rest Controller - слушает POST, PUT, DELETE, PATCH
- Commands Handler - исполняет сами команды на изменение
- Есть БД, которая может быть при желании оптимизирована для write операций.
В Query:
- Rest Controller - GET
- Query Handler - извлекает
- БД может быть оптимизирована для READ операций. 
- Events Handler - узнаешь позже

Но если у нас при таком разделении две БД, то как бд из Query узнает информцию, которая была занесена в БД из Command? Здесь нам поможет очередь сообщений.
Когда Command сделал запись, то он делает publish event о том, что он изменил. Т.е. в этом evente содержится информация о том, что изменилось(например, обновили информацию о продукте каком-то и говорим, что теперь по такому продукту такая информация). И другие микросервисы могут слушать этот эвент и как-то реагировать.
![[Pasted image 20241115163429.png]]
Это и делает Query микросервис. Events Handler как раз слушает различные events, которые связаны с тем, что состояние БД могло измениться. И синхронизирует READ БД в соответствие с этими ивентами.
![[Pasted image 20241115163619.png]]
И в таком случае очень круто, что микросервисы даже не знают друг о друге! Т.е. нет никаких портов, куда отправлять event просто очередь. Мы получаем очень независимую структуру!

Подведем итог по типам сообщений в CQRS:
- Command - описываем желание изменить как-то состояние системы. Например, создать продукт.
- Query - описывает желание получение информации. 
- Event - уведомление о том, что состояние системы изменилось.
![[Pasted image 20241115164004.png]]

### Event Sourcing
Для изучения рассмотрим его в сравнении с тем, как происходит работа с БД в наших обычных приложениях.
Клиент делает запрос на созданеие product, мы сохраняем его в БД. Дальше клиент делает запрос на обновление и мы обновляем уже существующую запись в БД. Если он сделает еще один такой запрос на обновление - процесс повторится. Неважно сколько мы сделаем обновлений у нас в БД всегда будет храниться запись в самом последнем состоянии.
![[Pasted image 20241115164354.png]]

Теперь посмотрим, как все происходит в Event Sourcing.
Когда клиент делает запрос на создание нового продукта, мы обрабатываем этот запрос, например, добавляем в БД. Но помимо этого сохраняем event о его желании создать продукт. Например, это будет event = ProductCreatedEvent. Мы сохранили его в некоторую БД, которая называется Event Store. Дальше, если клиент захотел обновить сущность, то мы также сохраняем этот event в Event Store. И при следующем запросе клиента на обновление он также сохраняется в Event Store. Т.е. у нас помимо того, что в БД хранится актуальное состояние продукта(т.е. мы при запросах на изменения изменяем продукт в БД), еще и хранится история изменения продукта, причем реально в том порядке, в котором приходили запросы от клиента!
![[Pasted image 20241115164912.png]]
И это круто, поскольку у нас есть история изменения продукта и мы можем использовать ее для того, чтобы реконструировать состояние продукта до того, которое мы захотим, т.е. теперь знаем, как сделать откат!

### Рассмотрим, как Event Sourcing вклинивается в CQRS приложение
Приходит запрос в Command на создание продукта, Commands Handler создает event ProductCreatedEvent и сохраняет его в Event Store! Т.е. в эту БД мы как раз только пишем, поэтому и можем оптимизировать ее под такие нужды! После этого мы публикуем этот event в очередь, чтобы из этой очереди ег опрочитал Query и обновил информацию в своей БД!
![[Pasted image 20241115171328.png]]
Таким образом, главное главное отличие в БД в Command и в Query - это то, что в Command у нас хранится множество записей, которые связаны с одной сущностью, т.е. как она изменялась(ивенты изменения), а в Query в БД у нас хранится актуальная информация по сущности и сущностью связана всего 1 запись!

Сравним эти две БД:
![[Pasted image 20241115172034.png]]
1. Видим, что у нас для одной сущности в Event Store сразу последотвательность записей(events), в то время как в Read Database всего одна запись с актуальными данными сущности.
2. В Read Database хранится ВСЯ информация по сущности, а в Event Store только часть информация, причем сохранятся только то, что должны было измениться, например, при обновлении цены мы видим, что в eventPayload хранится только id и цена.

Также стоит рассказать о механизме Replay
![[Pasted image 20241115172736.png]]
Когда к нам приходит новый event по Update Product, то мы перед тем, как добавлять такой event реконструируем наш Product, выполняя все events, который хранятся в Event Store для того, чтобы прийти к актуальному состоянию продукта и только потом уже добавляем новый event по изменению. Может показаться, что это ударит по производительности, но на самом деле это происходит довольно быстро, а также в Axon есть механизм Snapshots(т.е. сохраняем какое-то состояние) и потом мы можем производить Replay, начиная с определенного snapshot.

Зачем нужен механизм Replay? Он удобен, когда произошел какой-то баг и мы можем выполнить replay до этого момента и посмотреть на текущее состояние сущености и оценить, в каком она была состоянии и почему случился баг при таком состоянии!

### Axon framework
Axon построен на принципах:
- domain-driven design
- secures
- event-driven
Вот такая схема у Axon:
![[Pasted image 20241115173726.png]]

Пришел запрос (command) мы обрабатываем этот запрос, сохраняем в event store event для этого запроса и паблишим этот event. Этот event слушает Event Handling Components и сохраняет изменения в БД. Т.е. имеем соотвествие с CQRS которое разбирали выше. (черный квадратик описывает как раз Query часть на скрине ниже)
![[Pasted image 20241115174503.png]]
Причем Axon дает выбор для БД для Event Store и Read DB для Query составляющей. Мы можем использовать как тот storage, который дает нам Axon, так и любую другую БД.


Axon также содержит дополнительную инфраструктуру - Axon Server. Он управляет всеми маршрутами ивентов и evet store.
![[Pasted image 20241115175143.png]]
Есть два версии Axon Server - standard и enterprise. Enterpise позволяет запускать кластер из Axon Servers. 

Мы можем зайти в веб версию Axon, в которой есть dashboard, где мы можем получать различную информацию:
![[Pasted image 20241115175501.png]]
![[Pasted image 20241115175516.png]]

Есть также Axon console, с помощью которой можно отслеживать performance наших микросервисов.
![[Pasted image 20241115175827.png]]

Мы даже можем посмотреть на диаграмму сообщений:
![[Pasted image 20241115180105.png]]