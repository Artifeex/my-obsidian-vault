### Конвенции именования
#### Command
 Create(verb) + Product(noun) + Command = CreateProductCommand
#### Query
FindProductsQuery
#### Event
ProductCreatedEvent
#### Event Handler Method
```java
@EventHandler
public void on(ProductCreatedEvent productCreatedEvent) {

}
```


### Что такое микросервисы?
![[Pasted image 20241115115220.png]]![[Pasted image 20241115115346.png]]
Spring Cloud - это environment, который предоставляет множество услуг для микросервисов, написанных на SpringBoot.
### Microservice vs Monolit
![[Pasted image 20241115115521.png]]
Монолит - это одно большое приложение, которое содержит в себе контроллеры, каждый из которых отвечает за какую-то функциональность. И если мы захотим изменить в каком-то контроллере код, то придется ребилдить все приложение, а это для очень больших монолитов может занимать приличное время.
В микросервисах же у нас есть маленькие веб-сервисы(просто приложенька отдельная), которые отвечают за свой функционал, как раньше это делали контроллеры. И плюсом является то, что они меньше, поэтому в них проще разобраться, каждый микросервис может быть написан на различных технологиях, в то время как монолит обязан быть написан на одном языке. 

Но сложностью в случае микросервисов является общение между компонентами. В монолите мы просто заимпортили один сервис в другой сервис и у нас все хорошо. 
Микросервисы чаще всего общаются по HTTP.
![[Pasted image 20241115120054.png]]
На диаграмме выше мы видим, что у нас есть клиенты, которые шлют HTTP запросы для работы с нашими сервисами. Красный квадрат - это как раз SpringCloud. В нем есть микросервис API Gateway - просто снова приложенька на Spring Boot. И другие составляющие - такж являеются просто приложениями. А также у нас есть множество микросервисов, которые уже общаются между собой по HTTP.
![[Pasted image 20241115120443.png]]
Еще важной составляющей для микросервисов является то, что мы можно отдельно их редеплоить и они могут жить независимо от других микросервисов.

Представим, что у нас есть монолит:
![[Pasted image 20241115120639.png]]
И он рос, рос и мы решили распилить его на микросервисы.
Когда мы создаем микросервисы, то у нас теперь для каждого микросервиса своя БД. Этот паттерн называется database per class. И другие микросервисы не могут лазить в БД нашего микросервиса.
![[Pasted image 20241115120806.png]]
Если нагрузка на какой-то микросервис растет, то мы можем запустить на одном hoste, на котоом работает микросервис сразу несколько инстансов этого микросервиса - такой паттерн называется multiple instances per host. И мы можем запускать сколько угодно микросервисов Products на одном сервере, поскольку у каждого из них свой port и поэтому они не конфликтуют.
![[Pasted image 20241115121015.png]]

Но у нас появляется проблема. Когда был монолит, то из-за того, что он был запущен в одном instance, то мы на клиенте знали его port и тогда понятно, куда отправлять наши HTTP запросы. Но теперь у нас несколько микросервисов, каждый занимается какими-то своими делами, так еще и есть возможность запуска сразу несколько одинаковых микросервисов(products), причем при таком запуске порты генерируется динамически, т.е. порт микросервиса мы можем узнать только при старте нашего микросервиса. 

Сначала решим проблему с тем, что клиент не знает порт. Эту проблему решает API Gateway - приложение, которое работает на известном порту и к нему и делает запрос клиент. Это приложение знает о наших микросервисах и их портах и будет перенаправлять запросы на соотвествующий микросервис. Но откуда оно их знает? Ведь мы сказали, что порты динамические и известны только при старте приложения. Для этого существует Eureka Service Discovery - еще одна программка, которую можно считать адресной книжкой, в которой хранится информация о микросервисах. Когда микросервис запускается, то он регистрируется в Eureka Service, чтобы сообщить как раз свой порт. И тогда API Gateway может спросить у Eureka порт нужного микросервиса для отправки. 

Разберемся теперь с вопросом о нескольких инстансах одного микросервиса. Мы их создали из-за повышенной нагрузки и теперь нам нужно распределить запросы по ним. Поэтому появляется Load Balancer, который и будет заниматься распределением нагрузки. Он может быть как встроен в API Gateway, так и быть отдельным объектом, с который API Gateway будет работать.
![[Pasted image 20241115121545.png]]

Решим еще одну проблему. У каждого микросервиса есть свой конфигурационный файлик, в котором могут находиться различные настройки. Поэтому нам бы хотелось иметь какой-то централизованное место, где мы могли бы настраивать эти конфигурации. Этим центральным местом будет Config Server, который позволит нам изменять какие-то конфигурации на лету, т.е. не придется отстанавливать микросервис для каких-то изменений
![[Pasted image 20241115133251.png]]

Мы рассмотрели 4 составляющие микросервисной архитектуры:
![[Pasted image 20241115133531.png]]
Но есть и множество других.

### Event-Driven microservice
Микросервисы могут общаться по обычному HTTP. Делаю request и получая Response. Этот подход подходит под множество usecases, но не всегда.
![[Pasted image 20241115133846.png]]

Но представим ситуацию, что есть микросервис А и он хочет доставить одно и то же сообщение сразу множеству микросервисов. В таком случае нам уже не поможет то общение, которое мы описали выше. Т.е. да, мы бы могли с каждым микросервисом так обменяться, но это долго, поскольку если микросервисов 10-ки, то это 10-ки отправок одних и тех же сообщений и ожидания ответов, а также могут добавляться новые микросервисы, которые также будут хотеть получать сообщения.

Поэтому решением является Event-Driven подход, в котором микросервис А отправляет сообщения в брокер сообщений, а другие читают из этого брокера. Такая модель еще называется Producer/Consumer или Publisher/Subscriber. 
![[Pasted image 20241115134314.png]]

Producer может отправлять различные типы сообщений или events, а consumer получает эти events. И как раз потому что producer publish event или message такая архитектура общения и называется event driver или message driven.

Также стоит заметить, что Event-Driven architecture является асинхронной! Т.е. Когда в микросервис А приходит какая-то команда, которую ему нужно выполнить, то он publish event в message broker и не дожидается того, когда этот event и главное КЕМ этот event будет обработан. Он свое дело сделал, принял команду и создал event, который уже другие должны обработать. И микросервис А не ожидает какого-то респонса от subsriber-ов. Он сразу после того, как запушил event отправляет response для того запроса, который к нему пришел. 
![[Pasted image 20241115135207.png]]

Причем еще стоит заметить, что если какой-то из consumers отвалится, то ничего не поломается, т.к. брокер, в который отправили event продолжит хранить сообщение у себя. И потом, когда consumer микросервис очнется, то он сможет без проблем прочитать сообщения из брокера.

В случае же не event driven подхода
![[Pasted image 20241115135713.png]]
Если микросервис B помрет, то микросервис А ничего сделать не может, ему нужно дождаться ответа.

### Transactions in microservice
В случае монолита с транзакциями работать довольно просто. Мы запустили транзакцию, выполняем внутри нее какие-то шаги и потом заканчиваем транзакцию. И если в течение транзакции произошла какая-то ошибка, то мы без проблем делаем rollback всех действий.
![[Pasted image 20241115140115.png]]

Но когда мы работаем в микросервисной архитектуре, в которой у каждого микросервиса своя БД - работа с транзакциями  становится намного сложнее. 

Пусть у нас пришел request в микросервис Orders для создания заказа, он в своей БД создал в таблице заказов заказ. Дальше он обращается к микросервису Products, который должен зарезервировать товар для пользователя, чтобы другие пользователи не могли купить. Поэтому микросервис Products в своей БД также изменяет данные по этому продукту, который заказал пользователь. Потом мы обращаемся к 3-му микросервису для получения информации о платежных данных пользователя. И потом обращаемся к микросервису оплаты и тут происходит ошибка! И что теперь делать ? У нас БД у Orders и Products находятся в неправильном состоянии, нужно все откатить. Но как? Теперь откаты требуют изменения в разных БД! 
![[Pasted image 20241115140702.png]]

Для решения таких проблем придуман паттерн Saga.
### Saga
Сага паттерн нужен для того, чтобы наладить консистентность данных между микросервисами в распределенных транзакциях.
Есть 2 способа для реализации Saga:
- Хореография
- Оркестрация

### Хореография
![[Pasted image 20241115151519.png]]
Клиент хочет сделать заказ и Order Microservice получил запрос на заказ. Он изменил у себя БД и когда закончил, то отправляется event Order Created в message broker. На этот event подписан Products Microservice. Когда этот event приходит, то начинает работать Products Microservice и изменят уже у себя БД и делает, что ему надо и затем publish event Product Reserved, который слушает уже третий микросервис. И т.д. 

Т.е. у нас получается, что event который мы отправляем тригерит начало работы другого микросервиса, который слушает этот эвент и потом этот другой микросервис создает event, который слушает третий и т.д. Т.е. эвенты тригерят работу. И это происходит в определенном порядке друг за другом! И мы можем считать весь этот цикл одной транзакцией, т.е. шаги на картинке от 1 до 8 - это одна транзакция.

И если на каком-то из шагов происходит ошибка, то мы rollback делаем этих всех операций.
Но как сделать rollback?   
Например, в Payment Microservice произошла ошибка. Тогда дальнешие шаги(5-8) уже конечно же не делаются, а Payment Microservice публикует Card Authorization Failed Event - этот event нужен как раз для того, чтобы запустить цепочку обратных операций, чтобы восстановить состояние системы. Этот Failed event слушает Products Microservice, который теперь может отменить свои локальные изменения в БД и после этого запаблишить еще один Failed Event, чтобы теперь Orders Microservice мог узнать что произошла ошибка и откатить изменения. После этого Orders Microsevice может запаблишить Rejected Event если захочет, если вдруг в нашей системе кто-то слушает такие эвенты для ведения статистики отказов или еще чего-либо.
![[Pasted image 20241115152213.png]]

Кратко - если какой-то из шагов в Saga Flow fails микросервисы начинают выполнять компенсирующие транзакции. Компенсирующие транзакции нужны как раз для того, чтобы отменить изменения, которые произошли в нашей системе. И компенсирующие транзакции выполняются в обратном порядке относительно исходных транзакций:
![[Pasted image 20241115152717.png]]
![[Pasted image 20241115152738.png]]
### Оркестрация
Разберемся сначала вариант, когда ошибок нет.

Первое отличие от хореографии - это то, что в одном из микросервисов есть сущность Saga, которая является как бы менеджером, который следит за исполнением бизнес логики другими микросервисами.  В Orders Service пришел HTTP запрос на заказ, он обработал этот запрос(мог добавить в БД сущность заказа) и после этого отправляет event 1. Order Created Event. Этот event слушает как раз Saga и после этого паблишит сообщение 2. Reserve Product Command. Это сообщение слушает Products Service, делает какую-то обработку, изменяет в БД что-нибудь и после того, как закончил отправляет 3. Product Reserverd Event. Этот event снова слушает saga и отправляет после него 4. Process Payment Command, которую уже слушает Payment Service и т.д.
![[Pasted image 20241115154416.png]]

Теперь разберем вариант, что будет, если произойдет ошибка, например, в Payment Service. Payment Service слушал 4. Process Paymend Command начал обрабатывать оплату и произошла ошибка, после этого он отправляет 7. Card Authorization Failed. Этот Event слушает сага и теперь ей нужно отправить компенсирующие эвенты, причем снова в обратном порядке тому, как изначально шли эвенты. Т.е. у нас до 4. Process Payment Command был event 3. Product Reserved Event, значит, мы должны отправить компенсирующую команду для этого эвента - 8. Cancel Product Reserved Command. Это сообщение слушает Products Service, он выполняет отмену действий с БД, которую совершил и после этого отправляет 9. Product Reserv Canceled Event, т.е. сообщает Saga, что он все сделал, чтобы отменить то, что изменил и после этого сага отправляет еще одну команду, чтобы ее послушал Orders Service и уже у себя отменил заказ. 
![[Pasted image 20241115154329.png]]

### С теорией понятно, но как все это реализовать? 
Это довольно сложно сделать с нуля, поэтому есть специальные фреймворки, которые решают эту проблему. Мы будем использовать Axon, который использует CQRS подход и отлично интегрируется со Spring.

### Что же такое CQRS
Command-Query Responsibility Segregation.

В CQRS отвественность компонентов разделяется на 2 части - Commands and Query.

Commands - описывают желание изменения состояния приложения(тригеры для выполнения действия). Например, createProduct или deleteProduct. Такие команды обычно представляют из себя HTTP запросы - POST, PUT, DELETE, PATCH. 
Query - запросы на получение какой-то информации. Это GET запросы.
![[Pasted image 20241115160858.png]]
На картинке выше мы можем заметить, что Commands и Query находятся в одном микросервисе. Если нам нужно масштабироваться, то мы можем разделить Commands и Query на два разных микросервиса! Первый микросервис будет обрабатывать commands, а второй микросервис queries. 
![[Pasted image 20241115162629.png]]
Один микросервис будет иметь End points, который будут принимать POST, PUT ... запросы, а второй - GET. Причем т.к. они теперь независимые, то мы можем в зависимости от нагрузки деплоить их независимо и добавлять инстанты. Например, если у нас много GET запросов, то мы можем увеличивать число инстансов Query микросервиса.

В Command:
- Rest Controller - слушает POST, PUT, DELETE, PATCH
- Commands Handler - исполняет сами команды на изменение
- Есть БД, которая может быть при желании оптимизирована для write операций.
В Query:
- Rest Controller - GET
- Query Handler - извлекает
- БД может быть оптимизирована для READ операций. 
- Events Handler - узнаешь позже

Но если у нас при таком разделении две БД, то как бд из Query узнает информцию, которая была занесена в БД из Command? Здесь нам поможет очередь сообщений.
Когда Command сделал запись, то он делает publish event о том, что он изменил. Т.е. в этом evente содержится информация о том, что изменилось(например, обновили информацию о продукте каком-то и говорим, что теперь по такому продукту такая информация). И другие микросервисы могут слушать этот эвент и как-то реагировать.
![[Pasted image 20241115163429.png]]
Это и делает Query микросервис. Events Handler как раз слушает различные events, которые связаны с тем, что состояние БД могло измениться. И синхронизирует READ БД в соответствие с этими ивентами.
![[Pasted image 20241115163619.png]]
И в таком случае очень круто, что микросервисы даже не знают друг о друге! Т.е. нет никаких портов, куда отправлять event просто очередь. Мы получаем очень независимую структуру!

Подведем итог по типам сообщений в CQRS:
- Command - описываем желание изменить как-то состояние системы. Например, создать продукт.
- Query - описывает желание получение информации. 
- Event - уведомление о том, что состояние системы изменилось.
![[Pasted image 20241115164004.png]]

### Event Sourcing
Для изучения рассмотрим его в сравнении с тем, как происходит работа с БД в наших обычных приложениях.
Клиент делает запрос на созданеие product, мы сохраняем его в БД. Дальше клиент делает запрос на обновление и мы обновляем уже существующую запись в БД. Если он сделает еще один такой запрос на обновление - процесс повторится. Неважно сколько мы сделаем обновлений у нас в БД всегда будет храниться запись в самом последнем состоянии.
![[Pasted image 20241115164354.png]]

Теперь посмотрим, как все происходит в Event Sourcing.
Когда клиент делает запрос на создание нового продукта, мы обрабатываем этот запрос, например, добавляем в БД. Но помимо этого сохраняем event о его желании создать продукт. Например, это будет event = ProductCreatedEvent. Мы сохранили его в некоторую БД, которая называется Event Store. Дальше, если клиент захотел обновить сущность, то мы также сохраняем этот event в Event Store. И при следующем запросе клиента на обновление он также сохраняется в Event Store. Т.е. у нас помимо того, что в БД хранится актуальное состояние продукта(т.е. мы при запросах на изменения изменяем продукт в БД), еще и хранится история изменения продукта, причем реально в том порядке, в котором приходили запросы от клиента!
![[Pasted image 20241115164912.png]]
И это круто, поскольку у нас есть история изменения продукта и мы можем использовать ее для того, чтобы реконструировать состояние продукта до того, которое мы захотим, т.е. теперь знаем, как сделать откат!

### Рассмотрим, как Event Sourcing вклинивается в CQRS приложение
Приходит запрос в Command на создание продукта, Commands Handler создает event ProductCreatedEvent и сохраняет его в Event Store! Т.е. в эту БД мы как раз только пишем, поэтому и можем оптимизировать ее под такие нужды! После этого мы публикуем этот event в очередь, чтобы из этой очереди ег опрочитал Query и обновил информацию в своей БД!
![[Pasted image 20241115171328.png]]
Таким образом, главное главное отличие в БД в Command и в Query - это то, что в Command у нас хранится множество записей, которые связаны с одной сущностью, т.е. как она изменялась(ивенты изменения), а в Query в БД у нас хранится актуальная информация по сущности и сущностью связана всего 1 запись!

Сравним эти две БД:
![[Pasted image 20241115172034.png]]
1. Видим, что у нас для одной сущности в Event Store сразу последотвательность записей(events), в то время как в Read Database всего одна запись с актуальными данными сущности.
2. В Read Database хранится ВСЯ информация по сущности, а в Event Store только часть информация, причем сохранятся только то, что должны было измениться, например, при обновлении цены мы видим, что в eventPayload хранится только id и цена.

Также стоит рассказать о механизме Replay
![[Pasted image 20241115172736.png]]
Когда к нам приходит новый event по Update Product, то мы перед тем, как добавлять такой event реконструируем наш Product, выполняя все events, который хранятся в Event Store для того, чтобы прийти к актуальному состоянию продукта и только потом уже добавляем новый event по изменению. Может показаться, что это ударит по производительности, но на самом деле это происходит довольно быстро, а также в Axon есть механизм Snapshots(т.е. сохраняем какое-то состояние) и потом мы можем производить Replay, начиная с определенного snapshot.

Зачем нужен механизм Replay? Он удобен, когда произошел какой-то баг и мы можем выполнить replay до этого момента и посмотреть на текущее состояние сущености и оценить, в каком она была состоянии и почему случился баг при таком состоянии!

### Axon framework
Axon построен на принципах:
- domain-driven design
- secures
- event-driven
Вот такая схема у Axon:
![[Pasted image 20241115173726.png]]

Пришел запрос (command) мы обрабатываем этот запрос, сохраняем в event store event для этого запроса и паблишим этот event. Этот event слушает Event Handling Components и сохраняет изменения в БД. Т.е. имеем соотвествие с CQRS которое разбирали выше. (черный квадратик описывает как раз Query часть на скрине ниже)
![[Pasted image 20241115174503.png]]
Причем Axon дает выбор для БД для Event Store и Read DB для Query составляющей. Мы можем использовать как тот storage, который дает нам Axon, так и любую другую БД.


Axon также содержит дополнительную инфраструктуру - Axon Server. Он управляет всеми маршрутами ивентов и evet store.
![[Pasted image 20241115175143.png]]
Есть два версии Axon Server - standard и enterprise. Enterpise позволяет запускать кластер из Axon Servers. 

Мы можем зайти в веб версию Axon, в которой есть dashboard, где мы можем получать различную информацию:
![[Pasted image 20241115175501.png]]
![[Pasted image 20241115175516.png]]

Есть также Axon console, с помощью которой можно отслеживать performance наших микросервисов.
![[Pasted image 20241115175827.png]]

Мы даже можем посмотреть на диаграмму сообщений:
![[Pasted image 20241115180105.png]]

### Eureka Discovery Service
Ее также называют Spring Cloud Netflix Eureka - т.к. Eureka сначала придумал Netflix для своих нужд, а потом она стала частью Spring Boot.
Что делает Eureka?
Она помогает микросервисам найти друг друга.

Представим, что у нас есть клиентское приложение. Оно хочет пообщаться с нашим Products микросервисом. Но для общения оно должно знать его адрес(IP + port). Если у нас всего 1 микросервис с определенным портом - то никаких проблем нет, нужно на клиента захардкодить порт и все будет работать. Но что, если мы хотим иметь возможность при необходимости поднимать новые инстансы микросервиса Products, как нам быть? Мы не можем на клиенте заранее знать все порты. Тут и помогает Eureka. Каждый раз при старте микросервис регистрирует себя в Eureka, передавая свой порт на котором он работает. И в Eureka теперь хранятся все адреса микросервисов. Причем, если мы решим, что нам больше не нужно часть инстансов, то Eureka просто удалит их из своего хранилища.
![[Pasted image 20241116170424.png]]

Но не решена проблема, что клиент не знает порты. Тут помогает API Gateway, адрес которого всегда определенный и в него клиент и делает свой запрос, когда хочет отправить запрос в Products микросервис. API Gateway узнает у Eureka адреса всех инстансов этого микросервиса, к которому сделал запрос клиент и с помощью Load Balancer балансирует нагрузку между несколькими инстансами одного и того же микросервиса.
![[Pasted image 20241116170818.png]]

### Реализация Eureka
Eureka - это полноценное приложение. Мы создаем Spring Boot приложение, добавляем зависимость Eureka Server и конфигурируем application.properties файл.

А потом уже в нашем микросервисе добавляем зависимости, указываем адрес, где работает eureka(он настраивается как раз в конфигурационном файле Eureka приложения). И навешиваем аннотацию @EnableDiscoveryClient
И дальше у Eureka есть UI, где мы можем смотреть зарегистрированные сервисы.
![[Pasted image 20241116193920.png]]


### Spring Cloud API Gateway
Когда клиент делает запрос, то ему нужно знать точку входа - этой точкой и является Spring Cloud API Gateway, внутри которого есть встроенный Load Balancer. IP адреса для отправки клиентских запросов на конкретные микросервисы Gateway получает из Eureka. Помимо этого у него есть доп функционал. Мы можем писать фильтры и добавлять новый функционал(похоже на фильтры из сервлетов), т.к. все запросы приходят на Gateway и выходят также из него! 
![[Pasted image 20241116202914.png]]


### Мы можем включить автоматический routing в нашем приложении ApiGateway
Для этого нужно использовать в настройках 
spring.cloud.gateway.discovery.locator.enabled=true
### Чтобы приложение каждый раз стартовало с рандомным портом, нужно в application.yml указать port : 0. Тогда мы сможем запускать несколько инстансов одного сервиса и у них будут разные порты, что важно, т.к. мы не можем запустить один и тот же сервис с одним и тем же портом 
![[Pasted image 20241118151128.png]]
Но чтобы в Eureka могли регаться сразу несколько микросервисов одного и того же приложения, то нужно добавить доп настройку в микросервис:
![[Pasted image 20241118151942.png]]
В dashboard у нас будет благодаря этому будет 2 микросервиса! Если мы так не сделаем, то при запуске еще одного инстанса одного и того же микросервиса из-за того, что id по умолчанию равно имени приложения, то просто перетрется информация по прошлому инстансу
![[Pasted image 20241118152432.png]]

### Load Balancing
По дефолту Spring Cloud Api Gateway использует встроенный Load Balancer - Ribbon.


### Axon Server
Axon Server можно всячески конфигурировать. Для этого нужно просто создать .properteis файлик в директории configuration. И запустить axon server java -jar aonserver.jar - но это если мы скачали jar-ник с axon сайта. 
https://docs.axoniq.io/axon-server-reference/v2024.1/axon-server/administration/admin-configuration/configuration/
![[Pasted image 20241118160346.png]]
Наиболее простые настройки, чисто для примера:
![[Pasted image 20241118160359.png]]
devmode - нужен для того, чтобы появилась кнопка в dashboard axona, чтобы можно было вручную чистить Event Store.

Запуск в докере
docker run --name axonserver -p 8024:8024 -p 8124:8124 -v "/home/user/IdeaProjects/docker-data/data":/axonserver/data -v "/home/user/IdeaProjects/docker-data/eventdata":/axonserver/eventdata -v "/home/user/IdeaProjects/docker-data/config":/axonserver/config axoniq/axonserver
![[Pasted image 20241118161615.png]]
И потом в диреткории config мы создаем файлик axonserver.properties и там прописываем настройки.

Конвенция для имени команд.
![[Pasted image 20241119090748.png]]
Например: Create(verb) + Product(noun) + Command = CreateProductCommand

Command - это просто POJO, в котором мы храним всю необходимую информацию для выполнения команды + id, который нужен для Axon, чтобы решать к какому объекту относится команда. Например, для создания продукта мы в command храним:
![[Pasted image 20241119091520.png]]

В команде по созданию продукта как раз храним такие же поля, т.к. они нужны для создания объекта Product:
![[Pasted image 20241119091107.png]]

В контроллере мы создаем объект команды и затем отправляем эту команду в Command Gateway, которая отправляет команду в  Command Bus по которой отправляются команды в обработчик команд!

Можно думать об Command Gateway - как об API, который позволяет отправлять команды.
А Command Bus приинмает эти команды и направляет уже в обработчики команд, которые мы напишем! Т.е. это диспетчек команд, как диспатчер сервлет, который принимает все запросы и направляет их в соответствующие контроллеры. Если для Command Bus не будет Command Handlera, который обрабатывает данную команду, то будет выброшено исключение.
Вот такая схемка:
![[Pasted image 20241119092243.png]]

Вот так выглядит контроллер пока что. Создали команду и отправили ее через commandGateway, который получили из DI.
![[Pasted image 20241119094022.png]]


У commandGateway есть два основных метода:
- send - отправили команду и нам возвращается CompletableFuture, который мы сможем использовать потом, когда команда выполнится.
- sendAndWait - отправили команду и ждем результата. Т.е. это блокирующий вызов.
![[Pasted image 20241119092636.png]]

### Aggregate класс
Aggregate класс - это сердце нашего приложения. Разберем его на примере Product. Он хранит внутри себя:
- Текущее состояние Product, т.е. как раз те поля title, price, quantity, которые мы определили для нашего продукта.
- Command Handlers - это те команды, которые будут поступать из Command Bus в наш Aggregate Object.
- Business Logic - при обработки команды может быть выполнена различная бизнес логика. Это может быть валидация, т.е. может быть попытка создать некорректный Product объект и тут же и будет вынесено решение о том, чтобы не создавать невалидный объект.
- Event Sourcing Handlers Methods - они обрабатывают events, который приходят из Event Store для восстановления объекта. Axon сначала создает полностью пустой Aggregate object, в котором пустое состояние. И дальше он использует Event Store из которого забирает events, связанные с aggregate object и выполняет events для того, чтобы реконструировать объект. Т.е. если пришла команда UpdateProductCommand, то для ее выполнения нужно сначала восстановить состояние Product перед тем как вызвать обновление.
![[Pasted image 20241119093209.png]]

![[Pasted image 20241119135628.png]]

Создадим aggregate класс для Product и в конструкторе обработаем в нем CreateProductCommand:
![[Pasted image 20241119100301.png]]
После валидации, если все прошло хорошо, то мы должны сделать publish event, чтобы о создании event все узнали! 
Именование для events:
![[Pasted image 20241119100234.png]]
В случае создания Product: ProductCreatedEvent

Создаем объект eventa, в нем мы сами решаем, что хотим хранить. В случае создание нам нужно сохранить все данные для того, чтобы в Query части нашего CQRS приложение можно было сохранить этот Product в БД, а для этого нужна вся информация!
![[Pasted image 20241119100718.png]]

Теперь мы должны запаблишить этот event. Сделаем это после валидации в конструкторе, который обрабатывает CreateProductCommand. Для этого создаем сам объект event, а потом используем AggregateLifecycle.apply метод, который публикует этот event. Но важно, что сначала этот event доходит до EventHandlers ВНУТРИ НАШЕГО ProductAggregate, чтобы мы могли узнать об этом изменении для изменения ProductAggregate объекта, а только потом он уходит наружу для других EventHandlers других классов!
![[Pasted image 20241119101241.png]]

Теперь напишем в ProductAggregate EventHandler, который обработает productCreatedEvent, который мы отправили вызовом AggregateLifecycle.apply

По Axon конвенции мы называем методы on и вешаем аннотацию @EventSourcingHandler в котором принимаем event, который обрабатываем. Внутри обработчиков мы должны быть нацелены только на обновление внутреннего состояние AggregateObject, а не выполнять какую-то бизнес логику! Для бизнес логики используем обработчик команд. Вот так выглядит метод, который будет обрабатывать productCreatedEvent внутри ProductAggregate:
![[Pasted image 20241119102153.png]]
Также мы внутри ProductAggregate храним состояние для Product, которое и будем обновлять внутри EventHandlers. И стоит заметить, что мы должны использовать productId и аннотацию @AggregateIdentifier! С помощью этого поля Axon как раз и понимает, как связать команду, которая к нему пришла с Aggregate объектом, внутри которого есть обработчики команд, которые будут обрабатывать эту команду.
![[Pasted image 20241119102135.png]]

Таким образом, что имем?
POST запрос приходит в контроллер, там мы создаем CommandCreateProduct и отправляем через CommandGateway эту команду. У команды должно быть поле:
```java
@TargetAggregateIdentifier 
private final String productId;
```
Чтобы Axon мог связать команду и AggregateObject.
Эта команда приходит в AggregateObject, в котором есть метод(или конструктор, как было в случае CreateProductCommand), помеченный аннотацией @CommandHandler и который в качестве параметра принимает эту команду. В нем мы выполняем всю бизнес логику, которую хотим - валидируем, например. 

И после этого, если все хорошо, то мы паблишим event через AggregateLifecycle.apply(), который сначала выполняется для методов, которые слушают Event внутри AggregateObject класса(такие методы помечены аннотацией @EventSourcingHandler), а потом уже публикуется для других слушателей event-а.

Далее выполняется код в @EventSourcingHandler, внутри которого мы обновляем внутреннее состояние AggregateObject. Также обязательное поле:
```java
@AggregateIdentifier  
private String productId;
```

### Теперь поработем с Query частью нашего CQRS
Мы научились немного работать с Command частью, теперь же нам нужно написать Query часть, которая будет сохранять product в БД. Помечаем аннотацией Component и создаем метод, который помечен @EventHandler для обработки ProductCreatedEvent и сохраняем его через обычный Jpa репозиторий.
![[Pasted image 20241119132738.png]]

Важно, что при старте нашего приложения @HandlerEvents автоматически начинает обрабатывать ивенты, которые не были обработаны ранее.

Для подключения к веб-интерфейсу h2 консоли используется /h2-console путь, но перед ним, если мы используем spring cloud api gateway, то нужно также указывать необходимый url.

Теперь реализуем схему с получением данных.
![[Pasted image 20241119132947.png]]

![[Pasted image 20241119135757.png]]
Стоит заметить, что у Query нет прослойки в виде Even Bus, как у Command API. 

В случае Query у нас приходит запрос на контроллер, в контроллере мы создаем Query объект(аналогия с Command объектом) и в этот Query объект мы уже помещаем информцию, которая необходима для query запроса(например, если реализуем пагинацию, то какую страницу отобразить и количество страниц). 

Созданный Query объект. Причем есть конвенция, которая также представлена на скрине:
![[Pasted image 20241119140230.png]]

QueryController, который как раз создает объект FindProductsQuery и передает его через gateway. В метод query вторым параметром передается то, что должен вернуться обработчик query. Т.к. нам нужен список, то мы используем ResponseTypes.multipleInstances. А возвращается нам future, поэтому join.
![[Pasted image 20241119140321.png]]


И дальше этот Query отправляем через QueryGateway на обработку в метод, помеченный аннотацией @QueryHandler(аналогия с @CommandHandler, который есть внутри AggregateObject). Внутри него мы общаемся с репозиторием и возвращаем то, что хотели вернуть из Query.

А вот и сам класс, внутри которого есть @QueryHandler метод
![[Pasted image 20241119140539.png]]


### Валидация информации перед сохранением в БД

#### Bean Validation
Сначала проверим переданные поля, т.е. произведем раннюю валидацию.
Используем Hibernate Validation(помечаем аннотациями поля)
![[Pasted image 20241119141553.png]]
Документация:
https://hibernate.org/validator/documentation/

Вот такой прикольный вывод ошибок мы получим, если включим две настройки в application.yml:
server:  
  error:  
    include-message: always  - добавляеn message в response(на скрине увидишь)
    include-binding-errors: always - добавляем errors(на скрине также увидишь)
![[Pasted image 20241119144502.png]]

#### Command Validation
Также валидация может потребоваться для команды, которую мы получили в @CommandHandler. Важно, что валидация должна происходить до того, как отправится Event. Зачем такая валидация? Она чаще всего используется для того, чтобы проверить, можно ли выполнить такую команду, основываясь на текущем состоянии AggregateObject. Например, пришла команда ReserveProductCommand - которая говорит, чтобы мы зарезервировали Product. Мы смотрим на текущее состояние нашего AggregateObject и если count у него меньше, чем хотят зарезервировать, то выбрасываем исключение!

Пример валидации, но конкретна этот вариант бесполезный, поскольку мы проверяем это на этапе Bean Validation(Hibernate Validator).
![[Pasted image 20241119144830.png]]


#### Message Dispatch Interceptor
Это еще один способ провалидировать команду. Но теперь уже не в @CommandHandler, а на этапе перед попаданием команды в Command Bus, а, значит, перед попаданием в метод @CommandHandler. Т.е. этот interceptor будет вызываться, когда мы будем отправлять команду через CommandGateway.
![[Pasted image 20241119145448.png]]
Что мы можем сделать в этом interceptore?
- Провалидировать команду
- Добавить в message какую-нибудь метаинформацию или прологировать команду!
- Заблокировать команду, выбросив исключение

Как реализовать Interceptor?
Создаем класс и реализуем MessageDispatchInterceptor
```java
@Component  
@Slf4j  
public class CreateProductCommandInterceptor implements MessageDispatchInterceptor<CommandMessage<?>> {  
  
    //Должен вернуть BiFunction, которая будет обрабатывать команду  
    //Integer - command index    // CommandMessage - result of the function    @Nonnull  
    @Override    public BiFunction<Integer, CommandMessage<?>, CommandMessage<?>> handle(  
            @Nonnull List<? extends CommandMessage<?>> messages  
    ) {  
        return (index, command) -> {  
  
            //прологируем вызванную команду  
            log.info("Intercepted Command: " + command.getPayload());  
  
  
            //Т.к. данный interceptor будет срабатывать для всех команд, которые мы отправляем, то должны проверить  
            //что это нужная команда.            if(CreateProductCommand.class.equals(command.getPayloadType())) {  
                if(command.getPayload() instanceof CreateProductCommand createProductCommand) {  
  
                    //Такую валидацию делаем чисто для примера, понятно, что это все можно проверить на этапе BeanValidation  
                    if(createProductCommand.getPrice().compareTo(BigDecimal.ZERO) <= 0) {  
                        throw new IllegalArgumentException("Price must be greater than zero");  
                    }  
  
                    if(createProductCommand.getTitle() == null || createProductCommand.getTitle().isEmpty()) {  
                        throw new IllegalArgumentException("Title can't be null or empty");  
                    }  
                }  
            }  
  
            return command;  
        };  
    }  
}
```
Но, чтобы он заработал мы должны зарегистрировать его(Создаем такой метод в любом @Configuration классе. Например, в main классе, где запускаем Spring приложение):
```java
// Мы должны зарегистрировать interceptor в CommandBus, чтобы он заработал  
@Autowired  
public void registerCreateProductCommandInterceptor(ApplicationContext context,  
                                                    CommandBus commandBus) {  
    commandBus.registerDispatchInterceptor(  
            context.getBean(CreateProductCommandInterceptor.class)  
    );  
  
}
```

#### Как проверить перед сохранением объекта, что такой объект еще не существует?
Проблема в том, что мы разделили Command и Query. Сохраняем объект мы в Command части, но нам нужно в ней же сделать запрос, которым проверить нет ли такого объекта в БД? Но как мы должны это сделать, вызовом Query? Или самим сходить в Repository? Или какой-то другой вариант? 

Эта проблема описана в одной из статьей на Axon сайте.
![[Pasted image 20241119161549.png]]

Для решения этой проблемы мы заведем в Command части приложения еще одну БДшку - Lookup DB. Она будет хранить только productId и title! А все другие поля она не будет хранить, т.к. единственная цель этой БД - дать нам возможность в Command проверить при создании или обновлении Product, что такой Product существует. Но где мы будем это проверять ? Мы будет это проверять как раз в Interceptore, который написали ранее, который выполняется до того, как Command попадет в CommandHandler. 

Еще важно то, что наша Lookup табличка должна быть синхроинизированна с другой основной БД, т.е. чтобы данные в них по id и title совпадали(title у нас хранится в lookup, поскольку мы указали, что он unique, поэтому также нужно проверять.). Чтобы не было такого, что в lookup страничке нет какой-то инфы, либо наоборот. 

Т.е. мы дожны сохранять изменения как в lookup табличку, так и в основную БД. С основной БД понятно, когда все с командной хорошо, то паблишим event с изменением и потом в EventHandler обновляем БД. Но как поступить с lookup? А для нее мы также будем генерировать event для сохранения и в EventHandlere обрабатывать, но уже этот EventHandler будет в Command.
![[Pasted image 20241119162017.png]]

Создаем Entity, которую будем хранить в Lookup table:
```java
@Data  
@Entity  
@Table(name = "productlookup")  
public class ProductLookupEntity implements Serializable {  
  
    private static final long serialVersionUID = -1040059442356059255L;  
  
    @Id  
    @Column(unique = true)  
    private String productId;  
    @Column(unique = true)  
    private String title;  
}
```
И репозиторий:
![[Pasted image 20241119164403.png]]

@ProcessingGroup("product-group") - для логического объединения всех EventHandlers, которые обрабатывают events, связанные с Product.
Axon для каждой такой группы создает отдельный tracking event processor. Этот tracking event processor будет использовать специальный tracking token, который будет использовать для избежания множественной обработки одного и того же эвента в разных тредах и нодах. Также этот механизм используется для Rollback операций. (Стоит почитать отдельно, зачем это нужно). 

Как я понял - это еще нужно для того, чтобы в том потоке, в котором инициировался этот event выполнилась и его обработка, чтобы не было такого, что мы в нашем потоке создали эвент, а он обработался и другим потоком и нашим. Но лучше реально почитать об этом...

Но похоже поведение зависит еще и от типа Tracking Event Processor. 

ProductLookupEventsHandler - event handler на событие CreateProductEvent. Он должен добавить в lookup БД новую сущность. Почему он не проверяет? Потому что мы делаем проверку на то, существует сущность или нет в interceptore, который вызывается раньше, чем EventHandler. 
```java
@Component  
@ProcessingGroup("product-group") // чтобы логически объединить все handler-ы, которые обрабатывают Product эвенты в одну группу  
@RequiredArgsConstructor  
@Slf4j  
public class ProductLookupEventsHandler {  
  
    private final ProductLookupRepository productLookupRepository;  
  
    @EventHandler  
    public void on(ProductCreatedEvent productCreatedEvent) {  
        log.error("ProductLookupEventsHandler");  
  
        ProductLookupEntity productLookupEntity = new ProductLookupEntity(  
                productCreatedEvent.getProductId(), productCreatedEvent.getTitle()  
        );  
        productLookupRepository.save(productLookupEntity);  
    }  
}
```

Код interceptora, который проверяет нет ли такой сущности уже в БД. Если есть, то выбрасывает исключение, а значит event-ы, которые инициируются уже после interceptora не будут вызваны.
```java
@Component  
@Slf4j  
@RequiredArgsConstructor  
public class CreateProductCommandInterceptor implements MessageDispatchInterceptor<CommandMessage<?>> {  
  
    private final ProductLookupRepository productLookupRepository;  
  
    //Должен вернуть BiFunction, которая будет обрабатывать команду  
    //Integer - command index    // CommandMessage - result of the function    @Nonnull  
    @Override    public BiFunction<Integer, CommandMessage<?>, CommandMessage<?>> handle(  
            @Nonnull List<? extends CommandMessage<?>> messages  
    ) {  
        return (index, command) -> {  
  
            //прологируем вызванную команду  
            log.info("Intercepted Command: " + command.getPayload());  
              
            //Т.к. данный interceptor будет срабатывать для всех команд, которые мы отправляем, то должны проверить  
            //что это нужная команда.            if (CreateProductCommand.class.equals(command.getPayloadType())) {  
                if (command.getPayload() instanceof CreateProductCommand createProductCommand) {  
                    ProductLookupEntity entity = productLookupRepository.findByProductIdOrTitle(  
                            createProductCommand.getProductId(),  
                            createProductCommand.getTitle()  
                    );  
                    if (entity != null) {  
                        throw new IllegalStateException(  
                                String.format("Product with productId %s or title %s already exists.",  
                                        createProductCommand.getProductId(), createProductCommand.getTitle())  
                        );  
                    }  
                }  
            }  
  
            return command;  
        };  
    }  
}
```

ProductEventsHandler - для сохранения Product в основную БД приложения.
```java
//также часто называют ProductProjection  
@Component  
@RequiredArgsConstructor  
@ProcessingGroup("product-group")  
@Slf4j  
public class ProductEventsHandler {  
  
    private final ProductsRepository productsRepository;  
  
    @EventHandler  
    public void on(ProductCreatedEvent event) {  
  
        log.error("ProductEventsHandler");  
        ProductEntity product = new ProductEntity();  
        BeanUtils.copyProperties(event, product);  
  
        productsRepository.save(product);  
    }  
}
```

Логика, которую имеем.
Приходит POST запрос от клиента о создании объекта. Мы создаем command CreateProductCommand и с помощью CommandGateway отпраляем ее на обработку. У нас есть interceptor, который вызывается для каждой команды и для CreateProductCommand проверяет, нет ли в Lookup БД уже такой сущности. Если она есть, значит, ошибка, т.к. создавать дубликаты запрещено. Говорим пользователю об ошибке и заканчиваем работу. После прохождения interceptora команда идет в AggregateObject, конструктор которого помечен аннотацией CommandHandler и он хендлит эту команду. После чего вызывает event через AggregateLifecycle, который сначала попадает в @EventSourcingHandler, в котором обновляются поля для AggregateObject. После чего этот эвент попадает в ProductLookupEventsHandler для сохранения нового Product в Lookup БД, а потом в ProductEventsHandler и сохраняется уже в полноценную БД для Query.

### Error Handling
Научимся наконец-то отменять изменения в БД. Т.е. если вдруг в Evente(а это уже последний этап, где мы реально уже изменяем в БД данные) произошла ошибка.
Для начала научимся отменять изменения внутри одного микросервиса, а потом уже и для распределенных транзакций с сага.

В try catch, который мы можем повесить в controller или используя @ControllerAdvice мы можем отлавливать ошибки, которые произошли в контроллере, в interceptore или в CommandHandlere. Но мы не можем обработать ошибку, которая произошла в EventHandler. Причем стратегия ошибок в Event Handlers такая, что если выбросилось исключение, то сообщение об ошибке запоминается, но выполнение ПРОДОЛЖАЕТСЯ В ДРУГИХ Event Handlers. Т.е. в моем handlere произошла ошибка и я дальше выполниться не смог, а вот другие без проблем смогут обрабатывать этот event, хотя это неправильно! Мы должны остановить обработку ошибочного эвента.

Причем commandHandler, который вызвал publish эвента уже никак не реагирует, для него все закончилось хорошо и в Controller не вернется никакой ошибки и мы отправим пользователю успешный ответ, хотя на самом деле в Event Handlere произошла ошибка!

Нам никто не мешает исползовать try catch внутри Event Handler методов, но проблема в том, что об этой ошибке никак не узнает controller. А мы бы хотели, чтобы она дошла до контроллера и была обработана! Для этого нужно будет использовать ListenerInvocationErrorHandler

Благодаря нему, когда ошибка произойдет, то мы остановим выполнение того Event Handlera, в котором произошла ошибка, а также остановим выполнение других Event Handlers, которые также обрабатывали этот event!!! А также сможем вернуть ошибку RestController классу и он вернет пользователю сообщение об ошибке! А также вся транзакция сделает rollback и откатятся все изменения! 

И чтобы все это работало нам и нужно, чтобы Event Handlers, которые обрабатывают одни и те же events находились в одной группе, которую обрабатывает Subscribing Event Processor.
![[Pasted image 20241119181432.png]]

### Что такое event processor?
Event Processor - это компонент, который направлен на выполнение технических аспектов, связанных с предоставлением эвентов до наших event handlers!
Есть два вида event processors:
![[Pasted image 20241119182202.png]]
#### Tracking
Это такой event processor, который работает в отдельном потоке от потока, который создает эвенты. Он забирает сообщения из источники эвентов.

Если произойдет ошибка, то он перейдет в Error мод Он отпустит token и затем будет пытаться выполнить этот эвент еще раз с увеличивающимся периодом, начиная с 1 секунды до 60 секунд. Т.е. он попробует перевыполнить event, если не получилось, то он удваивает время через которое попробует еще раз, т.е. уже через 2 секунды и снова попробует выполнить, если не получилось, то через 4 секунды и т.д. до того, пока не превысит 60 секунд.
Зачем такие периоды ожидания? Они нужны для того, чтобы если вдруг другая node сможет обработать event, то она смогла запросить token у нашего Tracking Processor-a и завершить обработку eventa.
#### Subscribing
Это такой event processor, который работает в том же потоке, который создает эвенты! Т.е. грубо говоря, в Aggregate мы вызвали event и этот же поток, который создает event отвечает и за доставку этого эвента в @EventHandler.

Если прозойдет ошибка, то сообщит о ней в компонент, который предоставил этот event(до паблишера этого эвента). Т.е. Subscribing позволит паблишеру обработать ошибку. Если мы распространим(propagate) ошибку до конца, то сможем откатить ее!

В курсе мы будем для отката ошибки использовать Subscribing вариант.

#### Что будет, если выбросить исключение в CommandHandler или QueryHandler?
Axon Framework оборачивает исключение либо в CommandExecutionException либо в QueryExecutionException в зависимости от того, где произошло исключение. 

Несмотря на то, что код с выбрасыванием исключения, идет после вызова метода apply, productCreatedEvent не запаблишится.
Axon Framework не сразу начинает выполнять передачу eventa, а сохраняем эвент для последующего выполнения, поэтому если потом выбросилось исключение, то productCreatedEvent не будет сохранен в Event Store и произойдет Rollback
![[Pasted image 20241120103741.png]]
И мы можем отловить ошибку, которая произошла в CommandHandlere в нашем @RestControllerAdvice:
Отловим эту ошибку
![[Pasted image 20241120110537.png]]
И в ответе видим, что в message у нас пишется, что ошибка произошла в @CommandHandler
![[Pasted image 20241120110523.png]]

#### А как обработать исключение, которое произошло глубже в EventHandlere, а не в CommandHandlere? Как мы говорили ранее, такое исключение уже не поднимается до @RestControllerAdvice или CommandHandler(без дополнительного кода)
Самый просто вариант внутри EventHandlera использовать try catch, а также, у нас есть аннотация @ExceptionHandler(но теперь не от Spring, а от Axon Framework). Работает аналогично, если где-то в EventHandlere выбросится исключение, то мы его можем обработать в методе с аннотацией  @ExceptionHandler

```java
@Component  
@RequiredArgsConstructor  
@ProcessingGroup("product-group")  
@Slf4j  
public class ProductEventsHandler {  
  
    private final ProductsRepository productsRepository;  
  
    @ExceptionHandler(resultType = IllegalArgumentException.class)  
    public void handle(IllegalStateException ex) {  
        //log error message  
    }  
  
    @ExceptionHandler(resultType = Exception.class)  
    public void handle(Exception ex) {  
        //log error message  
    }  
  
    @EventHandler  
    public void on(ProductCreatedEvent event) {  
  
        log.error("ProductEventsHandler");  
        ProductEntity product = new ProductEntity();  
        BeanUtils.copyProperties(event, product);  
  
        productsRepository.save(product);  
    }  
}
```
Важно, что эти хендлеры работают только внутри этого класса! Т.е. если в другом EventHandlere произойдет исключение, то они не обработают его.

НОО, если мы хотим, чтобы rollback прозошел и отменились все изменения, которые выполнились, то мы не должны их обрабатывать так, или же обрабатывать для логирования, но потом пробрасывать снова, чтобы, используя, доп механизмы это исключение всплыло наверх!

Это возможно, если для нашей группы events, мы используем subscribe event processor, потому что как мы узнали, subsribe event processor работает в том же потоке, в котором эти эвенты и генерируются и выполняются и поэтому он может выполнить rollback.

Для обработки ошибок в эвентах мы можем как написать кастомный обработчик, так и использовать стандартный, если нам не нужен никакой дополнительный функционал.

Для примера напишем кастомный, но он по сути делает то же самое, что и стандартный - пробрасывает исключение дальше, но при желании могли добавить какую-то логику.
```java
public class ProductsServiceEventsErrorHandler implements ListenerInvocationErrorHandler {  
  
    @Override  
    public void onError(@Nonnull Exception exception,  
                        @Nonnull EventMessage<?> event,  
                        @Nonnull EventMessageHandler eventHandler  
    ) throws Exception {  
        throw exception;  
    }  
}
```
И чтобы он заработал, нам нужно его зарегистрировать, также есть закомментированный код, который показывает, как взять стандартный обработчик.
```java
    //Регистрируем EventErrorHandler  
    @Autowired  
    public void configure(EventProcessingConfigurer configurer) {  
        configurer.registerListenerInvocationErrorHandler(  
                "product-group",  
                conf -> new ProductsServiceEventsErrorHandler()  
        );  
  
        //если нам не нужен кастомный EventHandler, а просто хотим, чтобы произошел Exception Propagation и выполнился rollback,  
        // то можем использовать стандартный, который предлагает нам Axon - PropagationErrorHandler.INSTANCE  
//        configurer.registerListenerInvocationErrorHandler(  
//                "product-group",  
//                conf -> PropagatingErrorHandler.INSTANCE  
//        );  
    }
```

Это все, что нужно, чтобы выполнить rollback транзакции(на самом деле, действия с БД даже не выполняются, т.е. если в debug моде пройтись и после вызова, например, метода save на репозитории посмотреть в БД, то там не будет изменений!) Также в EventStore не сохраняется эвент, который вызвал ошибку в EventHandlere.

Т.е. сейчас схема такая, что если выбросилось исключение в EventHandlere, то это исключение сначала перехватывается внутри @ExceptionHandler(который находится внутри класса, обрабатывающего исключения). Он пробрасывает это исключение еще выше, и оно попадает в класс, который реализует интерфейс ListenerInvocationErrorHandler, в котором мы также может что-нибудь сделать и должны пробросить его еще выше. После чего произойдет отмена изменений и exception пробросится на самый верх в @ControllerAdvice, в котором мы отлавливаем Exception. В каком из методов? В методы, который отлавливает CommandExecutionException.

### Saga Orchestration-based Saga
Saga - может быть как отдельным микросервисом, так и частью другого микросервиса. Чаще используется, когда она является частью. Но в какой микросервис ее добавить ? Добавляют в тот микросервис, который является стартом flow приложения. Например, если у нас сначала создается заказ в OrderService, потом выполняется код в ProductsService и потом уже PaymentService, то Saga добавляется к OrderService, т.к. он является стартовой точкой.

![[Pasted image 20241120143016.png]]

Сага класс помечается аннотацией @Saga.
Методы, которые ловят различные эвенты помечаются аннотацией @SagaEventHandler.

Также есть два метода, которые помечаются:
@StartSaga - данный метод по сути создает instance Saga. Т.е. когда приходит OrderCreatedEvent, то тогда и создается сага объект, если бы пометили какой-то другой метод, который принимает другой эвент, то сага instance создавался бы в том случае, когда приходил бы другой эвент. 

@EndSaga - помечается метод, принимающий эвент, после которого сага и ее транзакция является успешной и в дальнешем эвенты не будут обрабатывать этим saga instance.

Другими словами 
@StartSaga - начинает Saga Lifecycle
@EndSaga - оканчивает Saga Lifecycle

associationProperty - это проперти, по которому Axon Framework должен понять, какому saga инстансу передавать обработку эвента. У нас же может быть одновременно много saga instance, которые обрабатывают эвенты.



![[Pasted image 20241120151628.png]]

Saga.associateWith - и можем связать наш инстанс саги с еще каким-то ключом и значением!

Создали в OrdersService класс OrdersSaga, который принимает event и через commandGateway отправляет ReserveProductCommand, которую обрабатывает ProductAggregate
```java
@Saga  
@Slf4j  
public class OrdersSaga {  
  
    @Autowired  
    private transient CommandGateway commandGateway;  
  
    @StartSaga  
    @SagaEventHandler(associationProperty = "orderId")  
    public void handle(OrderCreatedEvent event) {  
        log.info("OrderCreatedEvent with orderId" + event.getOrderId() + " productId " + event.getProductId());  
        ReserveProductCommand reserveProductCommand = ReserveProductCommand  
                .builder()  
                .productId(event.getProductId())  
                .orderId(event.getOrderId())  
                .quantity(event.getQuantity())  
                .userId(event.getUserId())  
                .build();  
  
        commandGateway.send(reserveProductCommand, new CommandCallback<ReserveProductCommand, Object>() {  
  
            @Override  
            public void onResult(@Nonnull CommandMessage<? extends ReserveProductCommand> commandMessage,  
                                 @Nonnull CommandResultMessage<?> commandResultMessage  
            ) {  
                if(commandResultMessage.isExceptional()) {  
                    //start compensation transaction  
                }  
            }  
        });  
    }  
  
    @SagaEventHandler(associationProperty = "orderId")  
    public void handle(ProductReservedEvent productReservedEvent) {  
        log.info("ProductReservedEvent with orderId" + productReservedEvent.getOrderId() + " productId " + productReservedEvent.getProductId());  
        //Если такой event пришел в сагу, то, значит, что проблем при зарезервировании данных в products не было  
    }  
  
  
}
```

И самое интересное в том, что т.к. Axon Framework восстанавливает состояние ProductAggregate, то мы можем использовать quantity из него, а не идти в основную БД и получать из нее данные.
```java
@Aggregate  
@NoArgsConstructor //требуется для Axon, т.к. он для восстановления объекта ProductAggregate будет создавать сначала пустой объект  
public class ProductAggregate {  
  
    @AggregateIdentifier  
    private String productId;  
    private String title;  
    private BigDecimal price;  
    private Integer quantity;  
  
    //Т.к. команда по созданию product является по сути и инициатором создания Product Aggregate, поэтому мы используем конструктор для  
    //обработки этой команды! Т.к. логично, что без Product нет смысла и в Aggregate классе, которым связан с этим Product объектом    @CommandHandler  
    public ProductAggregate(CreateProductCommand createProductCommand) {  
        ProductCreatedEvent productCreatedEvent = new ProductCreatedEvent();  
        BeanUtils.copyProperties(createProductCommand, productCreatedEvent);  
  
        AggregateLifecycle.apply(productCreatedEvent);  
    }  
  
    @CommandHandler  
    public void handle(ReserveProductCommand reserveProductCommand) {  
        //Мы можем здесь использовать текущее состояние Aggregate объекта! Потому что Axon Framework, используя Event Store  
        //Сделает Replay наших эвентов в эвент сторе и тем самым восстановит состояние!        if(quantity < reserveProductCommand.getQuantity()) {  
            throw new IllegalArgumentException("Insufficient number of items in stock");  
        }  
  
        ProductReservedEvent productReservedEvent = ProductReservedEvent.builder()  
                .orderId(reserveProductCommand.getOrderId())  
                .productId(reserveProductCommand.getProductId())  
                .quantity(reserveProductCommand.getQuantity())  
                .userId(reserveProductCommand.getUserId())  
                .build();  
  
        AggregateLifecycle.apply(productReservedEvent);  
    }  
  
    @EventSourcingHandler  
    public void on(ProductCreatedEvent productCreatedEvent) {  
        this.productId = productCreatedEvent.getProductId();  
        this.title = productCreatedEvent.getTitle();  
        this.price = productCreatedEvent.getPrice();  
        this.quantity = productCreatedEvent.getQuantity();  
    }  
  
    @EventSourcingHandler  
    public void on(ProductReservedEvent productReservedEvent) {  
        this.quantity -= productReservedEvent.getQuantity();  
    }  
    }
```

![[Pasted image 20241121140529.png]]

Дальше сможешь посмотреть в проекте, но логика повторялась. Создаем микросервис, в нем создаем AggregateObject, который принимает команду, которую посылает сага, валидирует ее, а потом создает эвент, который проходит через цепочки event handlers, которые реально делают какие-то бизнес действия и если все хорошо, то этот эвент доходит в сагу.

### Saga. Compensating Transactions
![[Pasted image 20241121173152.png]]
Если произошла ошибка после передачи команды ProcessPaymentCommand, то мы должны выполнить компенсирующую транзакцию, чтобы отменить те действия, которые произошли до этой команды.
![[Pasted image 20241121173326.png]]
Также важным является то, что мы не должны делать компенсирующую транзакцию для шага, который не изменял как-либо нашу систему.
![[Pasted image 20241121173457.png]]
EventStore хранит эвенты, которые происходят в AggregateObject.
Важно заметить, что когда мы будем выполнять компенсирующую транзакцию, мы не должны пытаться удалить что-либо из event store. Если event произошел, то он сохранится в event store.

Причем если произошла какая-то ошибка при выполнении Saga, то нам не нужно удалять event из eventstore, мы просто создадим еще event, который также сохранится в event store.

### Deadlines
Deadline - это event, который произошел в том случае, если не произошел какой-то другой эвент, который мы ожидали.
Например, мы отправил команду и ожидаем, что event произойдет в течение 24 часов и придет к нам. Но если так произошло, что ожидаемый event не произошел в заданный период времени(те же 24 часа), то мы хотим, чтобы произошел другой event - deadline. Это полезно для компенсирования, т.к. в Saga flow какие-то шаги могут занимать долгое время, то если за определенное время что-то не произошло, то нужно компенсировать изменения, которые произошли в saga.

Deadline может быть использован как в Saga, так и в Aggregate классе.

Deadlien event - по сути является тригером либо для изменения какого-то проперти, либо инициатором rollback транзакции.

Если мы используем deadline в aggregate классе, то он не будет сохранен в event store.

Тригерится только 1 раз.
![[Pasted image 20241122092211.png]]

Для создания Deadline нужен сначала DeadlineManager. Есть более простой SimpleDeadlineManager и QuartzDeadlineManager
![[Pasted image 20241122092353.png]]
- SimpleDeadlineManager - сохраняет deadlines в оперативной памяти и если наш сервер рестартнется, то дедлайны потеряются.
- QuartzDeadlineManager - дополнительно сохраняет в памяти на диске и в случае рестарта дедлайны не потеряются.

Чтобы создать deadline нужно использовать как раз DeadlineManager, который мы создали на прошлом шаге и в нем указать название дедлайна, время, через которого он должен произойти и payload(т.е. какая-то доп инфорамия, если нужна для нашего дедлайна, например, для запуска компенсирующей команды, в которую нужно передалть информцию, которую нужно компенсировать)

Чтобы handle deadline создается @DeadlineHandler внутри которого указывается название дедлайна, указанного ранее при смоздании и принимает он в качестве параметра тот payload, который мы ожидаем.
![[Pasted image 20241122092822.png]]

А чтобы закенселить дедлайн в том случае, если ожидаемый эвент вызвался, то используем deadlineManager и кенселим. Причем можно как по id, так и закенселить все дедлайны по названию.
```java
private void cancelDeadline() {  
    if(scheduleId != null) {  
        deadlineManager.cancelSchedule(PAYMENT_PROCESSING_TIMEOUT_DEADLINE, scheduleId);  
        scheduleId = null;  
    }  
  
    //deadlineManager.cancelAll(PAYMENT_PROCESSING_TIMEOUT_DEADLINE); //отменяем дедлайн, поскольку обработка оплаты прошла  
}
```

### Subscription Query
Когда клиент вызвал Command, чтобы как-либо изменить состояние системы, то Read DB, которая находится на Query стороне не мгновенно получила изменения, мы же должны дождаться, когда придет event в query side, чтобы изменить уже БД. Но это занимает некоторое время и может получиться так, что клиент сразу же отправит запрос на получение той информации, которую он изменил, а она еще не изменилась и он получит старые данные. 

Для решения такой проблемы придумали SubscriptionQuery, которая возвращает клиенту текущее состояние системы(именно в ReadDB), но также позволяет пользователю подписаться на обновления того ресурса, который ему вернулся после Query запроса. И если какие-то обновления произошли, то мы сообщим пользователю об обновлении. 

И такая система будет работать, пока кто-нибудь не отменит подписку в subsription query.
![[Pasted image 20241122100548.png]]

И такая система может быть полезна для Saga. Мы можем сделать вызов COmmand, а потом получить результат уже вызовом Subsription Query. Т.е. когда Saga Flow закончится и обновление сделается, то мы можем сообщить пользователю о том, что все хорошо как раз с помощью subscription query.
![[Pasted image 20241122101002.png]]

Если мы хотим, чтобы наш Rest Controller дождался выполнения всего Saga Flow, то мы можем заинжектить в него Query Gateway, вызвать в нем subscription event и ждать, пока saga flow не закончится и не передаст нам updates и толкьо после этого мы вернем пользователю response.
![[Pasted image 20241122101241.png]]

```java
@PostMapping  
public OrderSummary createOrder(@Valid @RequestBody CreateOrderRestModel createOrderRestModel) {  
    String userId = "27b95829-4f3f-4ddf-8983-151ba010e35b";  
    String orderId = UUID.randomUUID().toString();  
  
    CreateOrderCommand createOrderCommand = CreateOrderCommand.builder()  
            .productId(createOrderRestModel.getProductId())  
            .quantity(createOrderRestModel.getQuantity())  
            .orderStatus(OrderStatus.CREATED)  
            .orderId(orderId)  
            .addressId(createOrderRestModel.getAddressId())  
            .userId(userId)  
            .build();  
  
    //1-то, что вернется в первый раз при первом вызове  
    //2-update query result - т.е. тот тип, в котором должны приходить обновления    SubscriptionQueryResult<OrderSummary, OrderSummary> queryResult = queryGateway.subscriptionQuery(new FindOrderQuery(orderId),  
            ResponseTypes.instanceOf(OrderSummary.class),  
            ResponseTypes.instanceOf(OrderSummary.class));  
  
    try {  
        commandGateway.sendAndWait(createOrderCommand);  
  
        //updates() - возвращает flux - это что-то, что описываем наш OrderSummary. Т.е. в этот flux будут приходить обновления  
        //blockFirst - блокирующее ожидание, ждем, пока в flux не придут обновления, а когда пришли, то все, возвращаем.        return queryResult.updates().blockFirst();  
    } finally {  
        queryResult.close();  
    }  
  
}
```

И чтобы отправить в subscriptionQuery мы в Saga используем 
```java
//чтобы в subscription query сообщить об обновлениях ошибках и что больше не будет обновлений  
@Autowired  
private transient QueryUpdateEmitter queryUpdateEmitter;
```

И в методах, которые заканчивают наш Saga Flow мы сообщаем в subsucriptionQuery результаты.
Причем и в случае неудачного эвента и в случае удачного
```java
@EndSaga  
@SagaEventHandler(associationProperty = "orderId")  
public void handle(OrderRejectedEvent orderRejectedEvent) {  
    log.info("OrderRejectedEvent with orderId" + orderRejectedEvent.getOrderId());  
    queryUpdateEmitter.emit(FindOrderQuery.class, query -> true,  
            new OrderSummary(orderRejectedEvent.getOrderId(), orderRejectedEvent.getStatus(), orderRejectedEvent.getReason()));  
}
```

```java
@EndSaga  
@SagaEventHandler(associationProperty = "orderId")  
public void handle(OrderApprovedEvent orderApprovedEvent) {  
    log.info("OrderApprovedEvent with orderId" + orderApprovedEvent.getOrderId());  
  
    //передаем в subscription query обновления  
    queryUpdateEmitter.emit(FindOrderQuery.class, query -> true,  
            new OrderSummary(orderApprovedEvent.getOrderId(), orderApprovedEvent.getOrderStatus(), ""));  
    //SagaLifecycle.end();  
}
```

И пользователь будет ждать ответа, а когда saga flow завершился, то получит такие результаты:
![[Pasted image 20241122104940.png]]

![[Pasted image 20241122105039.png]]

### Snapshotting
Snapshotting - это фича, которую предоставляет Axon Framework для того, чтобы оптимизировать загрузку events из event store. 
Напомним, как все работает.

В event store сохраняются все event-ы, которые как-либо изменяют состояние нашей бизнес сущности. Например, представим, что мы работаем с Product. Клиент вызвал создание нового продукта, мы создали команду, которую в AggregateObject приняли и создаем по сути новый AggregateObject и публикуем Event - ProductCreatedEvent. И вот этот event как раз сохранится в event store. И потом, когда пользователь захочет сделать обновление, то также вызовется команда, мы ее поймаем в AggregateObject, но теперь AggregateObject уже восстанавливается! Т.е. Axon создает сначала пустой AggregateObject(поля у него не заполнены значениями), а потом идет в EventStore, чтобы найти все event-ы, которые происходили с этим объектом и выполняет их последовательно(replay) и изменяет AggregateObject. В конце концов мы получаем AggregateObject, который соотвествует реальности(т.е. тому, что хранится в read БД).
![[Pasted image 20241122110530.png]]
Но с одним объектом может быть связано много изменений и тогда выполнение всех этих эвентов будет занимать много времени, чтобы восстановит состояние AggregateObject. (На самом деле на практике нечасто происходит такое, что какие-то сущности постоянно обновляются и плодится очень много эвентов с изменением этой сущности, но такие ситуации возникают). Поэтому и был придуман механизм Snapshots.

Мы можем настроить, когда Axon будет выполнять создание Snapshot. Это может быть раз в некоторый временной интервал(например, в конце дня) или после определенного числа event-ов, которые произошли с объектом или если загрузка текущего состояние объекта через последовательное выполнение операций в event store занимает больше времени, чем мы задали.

Сам механизм работы теперь такой, что Axon в зависимости от настройки создает Snapshot(по сути просто сериализует текущее состояние нашего AggregateObject и сохраняет его). И потом, когда нужно выполнить обновление, то он идет сразу в snapshots для нашего AggregateObject, восстанавливает его состояние через этот snapshot и не вызывает events, которые происходили до этого snapshot, через который мы восстановили наш AggregateObject.
![[Pasted image 20241122111454.png]]

Создаем бин - тригер, в котором как раз определяем, когда будет вызываться этот тригер по созданию снапшота. На примере ниже мы настроили так, что раз в 500 эвентов будет создаваться snapshot. 
![[Pasted image 20241122111917.png]]

И мы также указываем имя для этого бина, чтобы в AggregateObject настроить то, когда будут делаться snapshots:
![[Pasted image 20241122112127.png]]

Чтобы проследить, что происходит с event store мы можем либо воспользоваться dashboard axon, либо выбрать уровень логирования:
![[Pasted image 20241122112805.png]]

### Replaying Events
Одно из преимуществ использования Event-sourcing подхода - это то, что у нас хранится история изменения состояния нашего приложения. 
Благодаря этому мы можем заребилдить состояние нашей ReadDB.

EventStore - это источник правды! А вот ReadDB, это просто проекция этого источника на ReadБД. В Read DB мы храним просто текущее состояние нашей системы. 

С помощью Replaying Events мы просто будет выполнять эти эвенты с самого начала, т.е. по новой будут вызываться EventHandlers и восстанавливать состояние БД. Например, это может быть полезно, когда мы добавили новый столбец в таблицу - дата последнего обновления. При добавлении этот столбец будет пустым для всей таблицы. Но благодаря тому, что мы можем сделать Replaying Events, то мы сможем заполнить этот столбец!
![[Pasted image 20241122114234.png]]

Также полезным может быть, если мы решили создать новую БД, которая будет хранить какое-то другое представление нашей сущности, может быть, более сокращенное или наоборот подробное. Тогда мы создаем новые EventHandlers, которые уже будут работать с новой БД, а затем просим Axon произвести replaying events, тогда мы в этих хендлерах будет обновлять эту новую БД.

Также важным замечанием является то, что мы можем делать replaying не с нуля, а с определенного периода времени.
![[Pasted image 20241122114506.png]]

Особенности:
![[Pasted image 20241122114907.png]]
- @ResetHandler - можем пометить метод, который должен быть вызван перед тем, как будет произведен replay. Например, он может почистить БД, в которую мы будем потом через replay что-то добавлять
- Для реплеинга поддерживается только Tracking Event Processor, который нужно остановить перед реплеингом и почистить.
- DisallowReplay - чтобы не все event handlers срабатывали, поскольку, например, если какой-то event handler отвечал за отправку сообщений клиенту, то мы не хотим, чтобы это еще раз выполнилось.

Вот так выглядит процедура перезапуска в коде:
![[Pasted image 20241122120400.png]]
Но также нужно не забыть переключить на другом mod event processor для нашей группы, т.к. subscribing не поддерживает replaying функцию. Но мы можем временно включить tracking, чтобы выполнить replay, а потом обратно вернуть subscribing.
![[Pasted image 20241122120525.png]]

